{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H-dence U-Net\n",
    "---\n",
    "\n",
    "参考\n",
    "- 論文 [H-DenseUNet: Hybrid Densely Connected UNet for Liver and Tumor Segmentation from CT Volumes](https://arxiv.org/pdf/1709.07330.pdf)\n",
    "- 公式 [GitHubリポジトリ](https://github.com/xmengli999/H-DenseUNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../Preprocess/datasets/train-label/\n",
    "!ls ../Preprocess/datasets/train-image/\n",
    "!ls ../Preprocess/datasets/test-label/\n",
    "!ls ../Preprocess/datasets/test-image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mhd_files(path):\n",
    "    '''\n",
    "    指定ディレクトリの mhd 形式のファイルを読み込み、\n",
    "    1-1. 例の結合された配列 images の作成\n",
    "    1-2. images の各スライスごとに症例番号・スライス番号を格納した image_filesの作成\n",
    "    '''\n",
    "\n",
    "    mhd_files = natsorted(glob.glob(path+'*.mhd'))\n",
    "\n",
    "    # 1症例目のみ配列作成のため、単体で読み込み\n",
    "    images = SimpleITK.GetArrayFromImage(SimpleITK.ReadImage(mhd_files[0]))\n",
    "    image_files = []\n",
    "    for i in range(images.shape[0]):\n",
    "        image_files.append(mhd_files[0].split('/')[-1].split('.')[0] +'-'+str(i))    \n",
    "\n",
    "    # 以降の症例\n",
    "    for mhd_name in mhd_files:\n",
    "        mhd_array = SimpleITK.GetArrayFromImage(SimpleITK.ReadImage(mhd_name))\n",
    "        images = np.concatenate([images,mhd_array])\n",
    "        for i in range(mhd_array.shape[0]):\n",
    "            image_files.append(mhd_name.split('/')[-1].split('.')[0] +'-'+str(i))     \n",
    "\n",
    "    # 0-1に正規化\n",
    "    #images = (images-np.min(images)) / (np.max(images)/2) - 1\n",
    "\n",
    "    return images #, image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training images...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a5cd025c354ae7b2c287c49654bf33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2879), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(11516, 1, 512, 512)\n",
      "(11516, 1, 512, 512)\n",
      "Saving to train.npy files done.\n",
      "Creating testing images...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f212178b989f4d4dbd729c4ea9453515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=386), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(386, 1, 512, 512)\n",
      "(386, 1, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import SimpleITK\n",
    "import numpy as np\n",
    "from natsort import natsorted\n",
    "from matplotlib import pylab as plt\n",
    "from skimage.util import random_noise\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "\n",
    "class dataProcess(object):\n",
    "\n",
    "    def __init__(self, out_rows, out_cols, data_path  = \"../Preprocess/datasets/train-image/\",\n",
    "                                           label_path = \"../Preprocess/datasets/train-label/*/\",\n",
    "                                           test_path  = \"../Preprocess/datasets/test-image/\",\n",
    "                                           testlabel_path = \"../Preprocess/datasets/test-label/*/\"):\n",
    "\n",
    "        self.out_rows = out_rows\n",
    "        self.out_cols = out_cols\n",
    "        self.data_path = data_path\n",
    "        self.label_path = label_path\n",
    "        self.test_path = test_path\n",
    "        self.testlabel_path = testlabel_path\n",
    "\n",
    "    def _transform(self,imagein):\n",
    "        image = imagein\n",
    "        resize_image = cv2.resize(image, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "        if self.__channels and len(image.shape) < 3:  # make sure images are of shape(h,w,3)\n",
    "            image = np.array([image for i in range(3)])\n",
    "        else:\n",
    "            resize_image = image\n",
    "        return np.array(resize_image)\n",
    "\n",
    "    def horizontal_flip(img):\n",
    "        return img[:,::-1]\n",
    "\n",
    "    def vertical_flip(img):\n",
    "        return img[::-1,:]\n",
    "        \n",
    "    def upscale1_1_img(img):\n",
    "        scale = 563     # floor(512*1.1)\n",
    "        img = cv2.resize(img.astype(np.float64), (scale,scale), interpolation = cv2.INTER_NEAREST)\n",
    "        img = img[25:537,25:537]\n",
    "        img = img.astype(np.int32)\n",
    "        return img\n",
    "\n",
    "    def addnoise(img):\n",
    "        mean = 0\n",
    "        sigma = 50\n",
    "        gauss = np.random.normal(mean,sigma,(512,512))\n",
    "        img = img.astype(np.float64) + gauss\n",
    "        img = img.astype(np.int32)\n",
    "        return img\n",
    "    \n",
    "    def create_train_data(self):\n",
    "        '''\n",
    "        data_pathに存在する各症例を読み込み、rate倍のデータ拡張を行ったものを訓練データセットとする\n",
    "        '''\n",
    "        if not os.path.exists(\"trainImages.npy\"):\n",
    "            print('Creating training images...')\n",
    "\n",
    "            imgdatas= read_mhd_files(self.data_path)\n",
    "            num = len(imgdatas)\n",
    "            rate = 4\n",
    "            final_images = np.ndarray([num*rate,1,512,512],'int32')\n",
    "            imglabels = read_mhd_files(self.label_path)\n",
    "            final_label = np.ndarray([num*rate,1,512,512],'int32')\n",
    "            for i in tqdm(range(num)):\n",
    "                final_images[rate*i,0] = imgdatas[i]\n",
    "                final_images[rate*i+1,0] = dataProcess.horizontal_flip(imgdatas[i])\n",
    "                final_images[rate*i+2,0] = dataProcess.vertical_flip(imgdatas[i])\n",
    "                final_images[rate*i+3,0] = dataProcess.upscale1_1_img(imgdatas[i])\n",
    "                final_label[rate*i,0] = imglabels[i]\n",
    "                final_label[rate*i+1,0] = dataProcess.horizontal_flip(imglabels[i])\n",
    "                final_label[rate*i+2,0] = dataProcess.vertical_flip(imglabels[i])\n",
    "                final_label[rate*i+3,0] = dataProcess.upscale1_1_img(imglabels[i])\n",
    "\n",
    "\n",
    "            print(final_images.shape)\n",
    "            print(final_label.shape)\n",
    "            np.save(\"trainImages.npy\",final_images)\n",
    "            np.save(\"trainMasks.npy\", final_label)\n",
    "\n",
    "            #np.save(\"imgs_train.npy\", imgdatas)\n",
    "            #np.save(\"imgs_mask_train.npy\", imglabels)\n",
    "            print('Saving to train.npy files done.')\n",
    "\n",
    "    def create_test_data(self):\n",
    "        \n",
    "        if not os.path.exists(\"testImages.npy\"):\n",
    "            print('Creating testing images...')\n",
    "\n",
    "            imgdatas =  read_mhd_files(self.test_path)\n",
    "            num = len(imgdatas)\n",
    "            final_images = np.ndarray([num, 1, 512, 512],'int32')\n",
    "\n",
    "            imglabels =  read_mhd_files(self.testlabel_path)\n",
    "            final_label = np.ndarray([num, 1, 512, 512],'int32')\n",
    "            for i in tqdm(range(num)):\n",
    "                final_images[i, 0] = imgdatas[i]\n",
    "                final_label[i, 0] = imglabels[i]\n",
    "            print(final_images.shape)\n",
    "            print(final_label.shape)\n",
    "            np.save(\"testImages.npy\", final_images)\n",
    "            np.save(\"testMasks.npy\", final_label)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    mydata = dataProcess(512,512)\n",
    "    mydata.create_train_data()\n",
    "    mydata.create_test_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "# GPU1つのみの設定\n",
    "if 'tensorflow' == K.backend():\n",
    "    import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.visible_device_list = \"0\"\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2-NT",
   "language": "python",
   "name": "tf2-nt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
