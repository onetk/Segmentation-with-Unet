{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの作成\n",
    "---\n",
    "参考：\n",
    "- [all](http://ni4muraano.hatenablog.com/entry/2017/08/10/101053)\n",
    "- [batch normalization](https://www.kaggle.com/dingdiego/u-net-batchnorm-augmentation-stratification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers.convolutional import Conv2D, ZeroPadding2D, Conv2DTranspose\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose, ZeroPadding2D, ZeroPadding3D, AveragePooling3D\n",
    "from keras.layers import LeakyReLU, BatchNormalization, Activation, Dropout\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "\n",
    "class DenceUNet(object):\n",
    "    def __init__(self, input_channel_count, output_channel_count, first_layer_filter_count):\n",
    "        self.INPUT_IMAGE_SIZE = 512\n",
    "        self.CONCATENATE_AXIS = -1\n",
    "        self.CONV_FILTER_SIZE = 4\n",
    "        self.CONV_STRIDE = 2\n",
    "        self.CONV_PADDING = (1, 1)\n",
    "        self.DECONV_FILTER_SIZE = 2\n",
    "        self.DECONV_STRIDE = 2\n",
    "\n",
    "        # (512 x 512 x input_channel_count)\n",
    "        inputs = Input((self.INPUT_IMAGE_SIZE, self.INPUT_IMAGE_SIZE, input_channel_count))\n",
    "        conv11 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "        conv11 =  BatchNormalization()(conv11)\n",
    "        conc11 = concatenate([inputs, conv11], axis=3)\n",
    "        conv12 = Conv2D(32, (3, 3), activation='relu', padding='same')(conc11)\n",
    "        conv12 =  BatchNormalization()(conv12)\n",
    "        conc12 = concatenate([inputs, conv12], axis=3)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conc12)\n",
    "        \n",
    "        conv21 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "        conv21 =  BatchNormalization()(conv21)\n",
    "        conc21 = concatenate([pool1, conv21], axis=3)\n",
    "        conv22 = Conv2D(64, (3, 3), activation='relu', padding='same')(conc21)\n",
    "        conv22 =  BatchNormalization()(conv22)\n",
    "        conc22 = concatenate([pool1, conv22], axis=3)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(conc22)\n",
    "        \n",
    "        conv31 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "        conv31 =  BatchNormalization()(conv31)\n",
    "        conc31 = concatenate([pool2, conv31], axis=3)\n",
    "        conv32 = Conv2D(128, (3, 3), activation='relu', padding='same')(conc31)\n",
    "        conv32 =  BatchNormalization()(conv32)\n",
    "        conc32 = concatenate([pool2, conv32], axis=3)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(conc32)\n",
    "        \n",
    "        conv41 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "        conv41 =  BatchNormalization()(conv41)\n",
    "        conc41 = concatenate([pool3, conv41], axis=3)\n",
    "        conv42 = Conv2D(256, (3, 3), activation='relu', padding='same')(conc41)\n",
    "        conv42 =  BatchNormalization()(conv42)\n",
    "        conc42 = concatenate([pool3, conv42], axis=3)\n",
    "        pool4 = MaxPooling2D(pool_size=(2, 2))(conc42)\n",
    "        \n",
    "        conv51 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "        conv51 =  BatchNormalization()(conv51)\n",
    "        conc51 = concatenate([pool4, conv51], axis=3)\n",
    "        conv52 = Conv2D(512, (3, 3), activation='relu', padding='same')(conc51)\n",
    "        conv52 =  BatchNormalization()(conv52)\n",
    "        conc52 = concatenate([pool4, conv52], axis=3)\n",
    "\n",
    "        \n",
    "        up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conc52), conc42], axis=3)\n",
    "        conv61 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "        conv61 =  BatchNormalization()(conv61)\n",
    "        conc61 = concatenate([up6, conv61], axis=3)\n",
    "        conv62 = Conv2D(256, (3, 3), activation='relu', padding='same')(conc61)\n",
    "        conv62 =  BatchNormalization()(conv62)\n",
    "        conc62 = concatenate([up6, conv62], axis=3)\n",
    "\n",
    "        up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conc62), conv32], axis=3)\n",
    "        conv71 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "        conv71 =  BatchNormalization()(conv71)\n",
    "        conc71 = concatenate([up7, conv71], axis=3)\n",
    "        conv72 = Conv2D(128, (3, 3), activation='relu', padding='same')(conc71)\n",
    "        conv72 =  BatchNormalization()(conv72)\n",
    "        conc72 = concatenate([up7, conv72], axis=3)\n",
    "\n",
    "        up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conc72), conv22], axis=3)\n",
    "        conv81 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "        conv81 =  BatchNormalization()(conv81)\n",
    "        conc81 = concatenate([up8, conv81], axis=3)\n",
    "        conv82 = Conv2D(64, (3, 3), activation='relu', padding='same')(conc81)\n",
    "        conv82 =  BatchNormalization()(conv82)\n",
    "        conc82 = concatenate([up8, conv82], axis=3)\n",
    "\n",
    "        up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conc82), conv12], axis=3)\n",
    "        conv91 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "        conv91 =  BatchNormalization()(conv91)\n",
    "        conc91 = concatenate([up9, conv91], axis=3)\n",
    "        conv92 = Conv2D(32, (3, 3), activation='relu', padding='same')(conc91)\n",
    "        conv92 =  BatchNormalization()(conv92)\n",
    "        conc92 = concatenate([up9, conv92], axis=3)\n",
    "\n",
    "        conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conc92)\n",
    "        \n",
    "        self.DenceUNET = Model(inputs=[inputs], outputs=[conv10])\n",
    "        \n",
    "\n",
    "    def _add_encoding_layer(self, filter_count, sequence):\n",
    "        new_sequence = LeakyReLU(0.2)(sequence)\n",
    "        new_sequence = ZeroPadding2D(self.CONV_PADDING)(new_sequence)\n",
    "        new_sequence = Conv2D(filter_count, self.CONV_FILTER_SIZE, strides=self.CONV_STRIDE)(new_sequence)\n",
    "        new_sequence = BatchNormalization()(new_sequence)\n",
    "        return new_sequence\n",
    "\n",
    "    def _add_decoding_layer(self, filter_count, add_drop_layer, sequence):\n",
    "        new_sequence = Activation(activation='relu')(sequence)\n",
    "        new_sequence = Conv2DTranspose(filter_count, self.DECONV_FILTER_SIZE, strides=self.DECONV_STRIDE,\n",
    "                                       kernel_initializer='he_uniform')(new_sequence)\n",
    "        new_sequence = BatchNormalization()(new_sequence)\n",
    "        if add_drop_layer:\n",
    "            new_sequence = Dropout(0.5)(new_sequence)\n",
    "        return new_sequence\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.DenceUNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### その他関数定義\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "IMAGE_SIZE = 512\n",
    "TRAIN_PERCENTAGE = 0.8\n",
    "\n",
    "# 値を-1から1に正規化する関数\n",
    "def normalize_x(image):\n",
    "    # image = image/127.5 - 1\n",
    "    image = (image-np.min(image)) / (np.max(image)/2) - 1\n",
    "    return image\n",
    "\n",
    "\n",
    "# 値を0から1に正規化する関数\n",
    "def normalize_y(image):\n",
    "    image = image/255\n",
    "    return image\n",
    "\n",
    "\n",
    "# 値を0から255に戻す関数\n",
    "def denormalize_y(image):\n",
    "    image = image*255\n",
    "    return image\n",
    "\n",
    "\n",
    "# インプット画像を読み込む関数\n",
    "def load_X(folder_path, mode='train'):\n",
    "    import glob, SimpleITK\n",
    "    from natsort import natsorted\n",
    "    \n",
    "    mhd_files = natsorted(glob.glob(folder_path+'*.mhd'))\n",
    "    limits = int(len(mhd_files)*TRAIN_PERCENTAGE)\n",
    "\n",
    "    if mode=='test':\n",
    "        images = SimpleITK.GetArrayFromImage(SimpleITK.ReadImage(mhd_files[0]))\n",
    "        \n",
    "        image_files = []\n",
    "        for i in range(images.shape[0]):\n",
    "            image_files.append(mhd_files[limits].split('/')[-1].split('.')[0] +'-'+str(i))    \n",
    "\n",
    "        for mhd_name in mhd_files[(int(limits)+1):]:\n",
    "            mhd_array = SimpleITK.GetArrayFromImage(SimpleITK.ReadImage(mhd_name))\n",
    "            images = np.concatenate([images,mhd_array])\n",
    "            for i in range(mhd_array.shape[0]):\n",
    "                image_files.append(mhd_name.split('/')[-1].split('.')[0] +'-'+str(i))  \n",
    "                \n",
    "    else:\n",
    "        images = SimpleITK.GetArrayFromImage(SimpleITK.ReadImage(mhd_files[0]))\n",
    "        \n",
    "        image_files = []\n",
    "        for i in range(images.shape[0]):\n",
    "            image_files.append(mhd_files[0].split('/')[-1].split('.')[0] +'-'+str(i))    \n",
    "\n",
    "        for mhd_name in mhd_files[1:int(limits)]:\n",
    "            mhd_array = SimpleITK.GetArrayFromImage(SimpleITK.ReadImage(mhd_name))\n",
    "            images = np.concatenate([images,mhd_array])\n",
    "            for i in range(mhd_array.shape[0]):\n",
    "                image_files.append(mhd_name.split('/')[-1].split('.')[0] +'-'+str(i))     \n",
    "    \n",
    "    images = normalize_x(images[:, :, :, np.newaxis])\n",
    "    return images, image_files\n",
    "\n",
    "\n",
    "# ラベル画像を読み込む関数\n",
    "def load_Y(folder_path):\n",
    "    import glob, SimpleITK\n",
    "    from natsort import natsorted\n",
    "    \n",
    "    mhd_files = natsorted(glob.glob(folder_path+'*/*[!2].mhd'))\n",
    "    limits = int(len(mhd_files)*TRAIN_PERCENTAGE)\n",
    "    \n",
    "    images = SimpleITK.GetArrayFromImage(SimpleITK.ReadImage(mhd_files[0]))\n",
    "    for mhd_name in mhd_files[1:int(limits)]:\n",
    "        mhd_array = SimpleITK.GetArrayFromImage(SimpleITK.ReadImage(mhd_name))\n",
    "        images = np.concatenate([images,mhd_array])\n",
    "    \n",
    "    # GTの値の範囲が0-6だったので、1以上は1にしている\n",
    "    images = np.where(images >= 1 , 1 ,images)\n",
    "    return images[:, :, :, np.newaxis]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train/test部分\n",
    "---\n",
    "\n",
    "参考：\n",
    "- [クロスバリデーション](https://lp-tech.net/articles/Y56uo)\n",
    "- [モデルチェックポイント](https://blog.shikoan.com/keras-model-checkpoint-save-best-only/)\n",
    "- [その全て](https://keras.io/ja/callbacks/)\n",
    "\n",
    "- [multi GPU](http://tech.wonderpla.net/entry/2018/01/09/110000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.utils import multi_gpu_model #GPU 2枚用\n",
    "\n",
    "# GPU1つのみの設定\n",
    "if 'tensorflow' == K.backend():\n",
    "    import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.visible_device_list = \"1\"\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from natsort import natsorted\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import plot_model\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "\n",
    "# ダイス係数を計算\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true * y_pred)\n",
    "    return 2.0 * intersection / (K.sum(y_true) + K.sum(y_pred) + 1)\n",
    "\n",
    "# ロス関数\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1.0 - dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "# denceU-Netのトレーニングを実行する関数\n",
    "def train_denceunet():\n",
    "    \n",
    "    datasets = natsorted(glob.glob('../Preprocess/mhd/*'))\n",
    "    X_train, file_names = load_X('../Preprocess/mhd/', 'train')\n",
    "    Y_train = load_Y('../Preprocess/GroundTruth/')\n",
    "    \n",
    "    # in:1チャンネル out:1チャンネル\n",
    "    input_channel_count = 1\n",
    "    output_channel_count = 1\n",
    "\n",
    "    # 一番初めのConvolutionフィルタ枚数は64\n",
    "    first_layer_filter_count = 64\n",
    "    BATCH_SIZE = 2\n",
    "    NUM_EPOCH = 30\n",
    "\n",
    "    # denceU-Netの生成\n",
    "    network = DenceUNet(input_channel_count, output_channel_count, first_layer_filter_count)\n",
    "    model = network.get_model()\n",
    "    model.compile(optimizer=Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.000000199), metrics=['accuracy', dice_coef], loss=dice_coef_loss )\n",
    "    #model.compile(optimizer=Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.000000199), loss='binary_crossentropy', metrics=['accuracy'] )\n",
    "    #model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=['accuracy', dice_coef] )\n",
    "    \n",
    "    plot_model(model, to_file='model.png')   \n",
    "    model.summary()\n",
    "    \n",
    "    # GPU 2枚用\n",
    "    # parallel_model = multi_gpu_model(model, gpus=2)\n",
    "    # parallel_model.compile(optimizer=Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.000000199), metrics=[dice_coef], loss=dice_coef_loss )\n",
    "    # parallel_model.summary()\n",
    "    \n",
    "       \n",
    "    \n",
    "    # datasetsの数だけ回して、train/testの組み合わせを検証\n",
    "    # for i in range(len(datasets)):\n",
    "        # X_train, file_names = load_X('../Preprocess/mhd/', 'train')   \n",
    "    \n",
    "    # K-fold split validationデータの組み合わせ検証\n",
    "    kf = KFold(n_splits=12, shuffle=False)\n",
    "    for i, (train_index, eval_index) in enumerate(kf.split(X_train)):\n",
    "        X_tra, X_eval = X_train[train_index], X_train[eval_index]\n",
    "        Y_tra, Y_eval = Y_train[train_index], Y_train[eval_index]         \n",
    "\n",
    "        cp = ModelCheckpoint(\"weights/weights-\"+str(i)+\"crs-{epoch:02d}ep-{val_loss:.2f}loss.hdf5\",\n",
    "                             monitor=\"val_loss\", verbose=1, save_best_only=True, save_weights_only=False)\n",
    "        learning_history = model.fit(X_tra, Y_tra, batch_size=BATCH_SIZE, epochs=NUM_EPOCH, callbacks=[cp], validation_data=(X_eval, Y_eval))\n",
    "        model.save_weights('weights/weights-ver'+ str(i) +'.hdf5')\n",
    "        \n",
    "        # GPU 2枚用\n",
    "        # learning_history = parallel_model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=NUM_EPOCH, callbacks=[cp], validation_data=(X_eval, y_eval))\n",
    "        # parallel_model.save_weights('weights/weights-ver'+ str(i) +'.hdf5')  # <- ここだけ未確認(model.saveでok?)\n",
    "\n",
    "        \n",
    "        plt.plot(range(1, NUM_EPOCH+1), learning_history.history['dice_coef'], label=\"training\")\n",
    "        plt.plot(range(1, NUM_EPOCH+1), learning_history.history['val_dice_coef'], label=\"validation\")\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.ylim(0,1)\n",
    "        plt.grid(axis='y', color='lightgray')\n",
    "        plt.savefig('progress-crs#'+str(i)+'.png')\n",
    "        plt.clf()\n",
    "    \n",
    "\n",
    "# 学習後のdenceU-Netによる予測を行う関数\n",
    "def predict():\n",
    "    import cv2\n",
    "\n",
    "    # testDataフォルダ配下にleft_imagesフォルダを置いている\n",
    "    X_test, file_names = load_X('../Preprocess/mhd/', 'test')\n",
    "\n",
    "    input_channel_count = 1\n",
    "    output_channel_count = 1\n",
    "    first_layer_filter_count = 64\n",
    "    network = DenceUNet(input_channel_count, output_channel_count, first_layer_filter_count)\n",
    "    model = network.get_model()\n",
    "    model.load_weights('weights/weights-0crs-11ep-0.02loss.hdf5')\n",
    "    BATCH_SIZE = 8\n",
    "    Y_pred = model.predict(X_test, BATCH_SIZE)\n",
    "    \n",
    "    # 変な方向の断面図でないか、気になる！\n",
    "    print(Y_pred.shape)\n",
    "    \n",
    "    # testDataフォルダ配下にleft_imagesフォルダを置いている\n",
    "    save_path = 'DenceU-Net_DataSet/pred/'\n",
    "    if not os.path.exists(save_path): os.makedirs(save_path)\n",
    "\n",
    "    for i, y in enumerate(Y_pred):\n",
    "        cv2.imwrite(save_path+'prediction' + file_names[i] + '.png', denormalize_y(y))\n",
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#     train_denceunet()\n",
    "#     predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 512, 512, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 512, 512, 32) 320         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 512, 512, 32) 128         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 512, 512, 33) 0           input_3[0][0]                    \n",
      "                                                                 batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 512, 512, 32) 9536        concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 512, 512, 32) 128         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 512, 512, 33) 0           input_3[0][0]                    \n",
      "                                                                 batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 256, 256, 33) 0           concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 256, 256, 64) 19072       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 256, 256, 64) 256         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 256, 256, 97) 0           max_pooling2d_9[0][0]            \n",
      "                                                                 batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 256, 256, 64) 55936       concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 256, 256, 64) 256         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 256, 256, 97) 0           max_pooling2d_9[0][0]            \n",
      "                                                                 batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 128, 128, 97) 0           concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 128, 128, 128 111872      max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 128, 128, 128 512         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 128, 128, 225 0           max_pooling2d_10[0][0]           \n",
      "                                                                 batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 128, 128, 128 259328      concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 128, 128, 128 512         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 128, 128, 225 0           max_pooling2d_10[0][0]           \n",
      "                                                                 batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 64, 64, 225)  0           concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 64, 64, 256)  518656      max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 64, 64, 256)  1024        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 64, 64, 481)  0           max_pooling2d_11[0][0]           \n",
      "                                                                 batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 64, 64, 256)  1108480     concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 64, 64, 256)  1024        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 64, 64, 481)  0           max_pooling2d_11[0][0]           \n",
      "                                                                 batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 32, 32, 481)  0           concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 32, 32, 512)  2216960     max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 32, 32, 512)  2048        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 32, 32, 993)  0           max_pooling2d_12[0][0]           \n",
      "                                                                 batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 32, 32, 512)  4576256     concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 32, 32, 512)  2048        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 32, 32, 993)  0           max_pooling2d_12[0][0]           \n",
      "                                                                 batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTrans (None, 64, 64, 256)  1017088     concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 64, 64, 737)  0           conv2d_transpose_9[0][0]         \n",
      "                                                                 concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 64, 64, 256)  1698304     concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 64, 64, 256)  1024        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 64, 64, 993)  0           concatenate_55[0][0]             \n",
      "                                                                 batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 64, 64, 256)  2288128     concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 64, 64, 256)  1024        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)    (None, 64, 64, 993)  0           concatenate_55[0][0]             \n",
      "                                                                 batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DTran (None, 128, 128, 128 508544      concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)    (None, 128, 128, 256 0           conv2d_transpose_10[0][0]        \n",
      "                                                                 batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 128, 128, 128 295040      concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 128, 128, 128 512         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)    (None, 128, 128, 384 0           concatenate_58[0][0]             \n",
      "                                                                 batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 128, 128, 128 442496      concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 128, 128, 128 512         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_60 (Concatenate)    (None, 128, 128, 384 0           concatenate_58[0][0]             \n",
      "                                                                 batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DTran (None, 256, 256, 64) 98368       concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_61 (Concatenate)    (None, 256, 256, 128 0           conv2d_transpose_11[0][0]        \n",
      "                                                                 batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 256, 256, 64) 73792       concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 256, 256, 64) 256         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)    (None, 256, 256, 192 0           concatenate_61[0][0]             \n",
      "                                                                 batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 256, 256, 64) 110656      concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 256, 256, 64) 256         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_63 (Concatenate)    (None, 256, 256, 192 0           concatenate_61[0][0]             \n",
      "                                                                 batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DTran (None, 512, 512, 32) 24608       concatenate_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)    (None, 512, 512, 64) 0           conv2d_transpose_12[0][0]        \n",
      "                                                                 batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 512, 512, 32) 18464       concatenate_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 512, 512, 32) 128         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)    (None, 512, 512, 96) 0           concatenate_64[0][0]             \n",
      "                                                                 batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 512, 512, 32) 27680       concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 512, 512, 32) 128         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 512, 512, 96) 0           concatenate_64[0][0]             \n",
      "                                                                 batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 512, 512, 1)  97          concatenate_66[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 15,491,457\n",
      "Trainable params: 15,485,569\n",
      "Non-trainable params: 5,888\n",
      "__________________________________________________________________________________________________\n",
      "Train on 2115 samples, validate on 193 samples\n",
      "Epoch 1/30\n",
      "2115/2115 [==============================] - 277s 131ms/step - loss: 0.7642 - acc: 0.9047 - dice_coef: 0.2358 - val_loss: 0.8935 - val_acc: 0.9930 - val_dice_coef: 0.1065\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.89355, saving model to weights/weights-0crs-01ep-0.89loss.hdf5\n",
      "Epoch 2/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.5939 - acc: 0.9907 - dice_coef: 0.4061 - val_loss: 0.8594 - val_acc: 0.9943 - val_dice_coef: 0.1406\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.89355 to 0.85942, saving model to weights/weights-0crs-02ep-0.86loss.hdf5\n",
      "Epoch 3/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.5532 - acc: 0.9914 - dice_coef: 0.4468 - val_loss: 0.8281 - val_acc: 0.9878 - val_dice_coef: 0.1719\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.85942 to 0.82807, saving model to weights/weights-0crs-03ep-0.83loss.hdf5\n",
      "Epoch 4/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.5268 - acc: 0.9919 - dice_coef: 0.4732 - val_loss: 0.8030 - val_acc: 0.9933 - val_dice_coef: 0.1970\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.82807 to 0.80301, saving model to weights/weights-0crs-04ep-0.80loss.hdf5\n",
      "Epoch 5/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.5065 - acc: 0.9922 - dice_coef: 0.4935 - val_loss: 0.8661 - val_acc: 0.9936 - val_dice_coef: 0.1339\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.80301\n",
      "Epoch 6/30\n",
      "2115/2115 [==============================] - 270s 127ms/step - loss: 0.4906 - acc: 0.9925 - dice_coef: 0.5094 - val_loss: 0.8072 - val_acc: 0.9915 - val_dice_coef: 0.1928\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.80301\n",
      "Epoch 7/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.4803 - acc: 0.9927 - dice_coef: 0.5197 - val_loss: 0.8348 - val_acc: 0.9931 - val_dice_coef: 0.1652\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.80301\n",
      "Epoch 8/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.4671 - acc: 0.9929 - dice_coef: 0.5329 - val_loss: 0.8345 - val_acc: 0.9924 - val_dice_coef: 0.1655\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.80301\n",
      "Epoch 9/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.4526 - acc: 0.9931 - dice_coef: 0.5474 - val_loss: 0.8215 - val_acc: 0.9927 - val_dice_coef: 0.1785\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.80301\n",
      "Epoch 10/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.4404 - acc: 0.9933 - dice_coef: 0.5596 - val_loss: 0.8094 - val_acc: 0.9906 - val_dice_coef: 0.1906\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.80301\n",
      "Epoch 11/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.4337 - acc: 0.9935 - dice_coef: 0.5663 - val_loss: 0.8109 - val_acc: 0.9927 - val_dice_coef: 0.1891\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.80301\n",
      "Epoch 12/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.4218 - acc: 0.9936 - dice_coef: 0.5782 - val_loss: 0.8227 - val_acc: 0.9924 - val_dice_coef: 0.1773\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.80301\n",
      "Epoch 13/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.4114 - acc: 0.9938 - dice_coef: 0.5886 - val_loss: 0.8035 - val_acc: 0.9924 - val_dice_coef: 0.1965\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.80301\n",
      "Epoch 14/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.4007 - acc: 0.9940 - dice_coef: 0.5993 - val_loss: 0.8287 - val_acc: 0.9937 - val_dice_coef: 0.1713\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.80301\n",
      "Epoch 15/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.3941 - acc: 0.9942 - dice_coef: 0.6059 - val_loss: 0.8289 - val_acc: 0.9930 - val_dice_coef: 0.1711\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.80301\n",
      "Epoch 16/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.3860 - acc: 0.9943 - dice_coef: 0.6140 - val_loss: 0.8471 - val_acc: 0.9936 - val_dice_coef: 0.1529\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.80301\n",
      "Epoch 17/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.3797 - acc: 0.9945 - dice_coef: 0.6203 - val_loss: 0.8292 - val_acc: 0.9923 - val_dice_coef: 0.1708\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.80301\n",
      "Epoch 18/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.3646 - acc: 0.9947 - dice_coef: 0.6354 - val_loss: 0.8220 - val_acc: 0.9928 - val_dice_coef: 0.1780\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.80301\n",
      "Epoch 19/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.3584 - acc: 0.9948 - dice_coef: 0.6416 - val_loss: 0.8292 - val_acc: 0.9937 - val_dice_coef: 0.1708\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.80301\n",
      "Epoch 20/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.3500 - acc: 0.9949 - dice_coef: 0.6500 - val_loss: 0.8234 - val_acc: 0.9929 - val_dice_coef: 0.1766\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.80301\n",
      "Epoch 21/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.3443 - acc: 0.9951 - dice_coef: 0.6557 - val_loss: 0.8461 - val_acc: 0.9935 - val_dice_coef: 0.1539\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.80301\n",
      "Epoch 22/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.3314 - acc: 0.9952 - dice_coef: 0.6686 - val_loss: 0.8375 - val_acc: 0.9932 - val_dice_coef: 0.1625\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.80301\n",
      "Epoch 23/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.3291 - acc: 0.9953 - dice_coef: 0.6709 - val_loss: 0.8376 - val_acc: 0.9935 - val_dice_coef: 0.1624\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.80301\n",
      "Epoch 24/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.3207 - acc: 0.9955 - dice_coef: 0.6793 - val_loss: 0.8248 - val_acc: 0.9928 - val_dice_coef: 0.1752\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.80301\n",
      "Epoch 25/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.3092 - acc: 0.9956 - dice_coef: 0.6908 - val_loss: 0.8538 - val_acc: 0.9940 - val_dice_coef: 0.1462\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.80301\n",
      "Epoch 26/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.3050 - acc: 0.9957 - dice_coef: 0.6950 - val_loss: 0.8501 - val_acc: 0.9938 - val_dice_coef: 0.1499\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.80301\n",
      "Epoch 27/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.3009 - acc: 0.9958 - dice_coef: 0.6991 - val_loss: 0.8291 - val_acc: 0.9932 - val_dice_coef: 0.1709\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.80301\n",
      "Epoch 28/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2911 - acc: 0.9960 - dice_coef: 0.7089 - val_loss: 0.8441 - val_acc: 0.9940 - val_dice_coef: 0.1559\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.80301\n",
      "Epoch 29/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2868 - acc: 0.9960 - dice_coef: 0.7132 - val_loss: 0.8386 - val_acc: 0.9935 - val_dice_coef: 0.1614\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.80301\n",
      "Epoch 30/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2805 - acc: 0.9961 - dice_coef: 0.7195 - val_loss: 0.8308 - val_acc: 0.9935 - val_dice_coef: 0.1692\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.80301\n",
      "Train on 2115 samples, validate on 193 samples\n",
      "Epoch 1/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.3134 - acc: 0.9960 - dice_coef: 0.6866 - val_loss: 0.3510 - val_acc: 0.9958 - val_dice_coef: 0.6490\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.35099, saving model to weights/weights-1crs-01ep-0.35loss.hdf5\n",
      "Epoch 2/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.3035 - acc: 0.9961 - dice_coef: 0.6965 - val_loss: 0.3494 - val_acc: 0.9957 - val_dice_coef: 0.6506\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.35099 to 0.34943, saving model to weights/weights-1crs-02ep-0.35loss.hdf5\n",
      "Epoch 3/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2959 - acc: 0.9962 - dice_coef: 0.7041 - val_loss: 0.3623 - val_acc: 0.9956 - val_dice_coef: 0.6377\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34943\n",
      "Epoch 4/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2894 - acc: 0.9963 - dice_coef: 0.7106 - val_loss: 0.3650 - val_acc: 0.9956 - val_dice_coef: 0.6350\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34943\n",
      "Epoch 5/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2847 - acc: 0.9964 - dice_coef: 0.7153 - val_loss: 0.3637 - val_acc: 0.9956 - val_dice_coef: 0.6363\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.34943\n",
      "Epoch 6/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2781 - acc: 0.9965 - dice_coef: 0.7219 - val_loss: 0.3614 - val_acc: 0.9956 - val_dice_coef: 0.6386\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.34943\n",
      "Epoch 7/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2733 - acc: 0.9966 - dice_coef: 0.7267 - val_loss: 0.3630 - val_acc: 0.9956 - val_dice_coef: 0.6370\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.34943\n",
      "Epoch 8/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2655 - acc: 0.9966 - dice_coef: 0.7345 - val_loss: 0.3710 - val_acc: 0.9954 - val_dice_coef: 0.6290\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.34943\n",
      "Epoch 9/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2670 - acc: 0.9967 - dice_coef: 0.7330 - val_loss: 0.4361 - val_acc: 0.9945 - val_dice_coef: 0.5639\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.34943\n",
      "Epoch 10/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2561 - acc: 0.9968 - dice_coef: 0.7439 - val_loss: 0.3830 - val_acc: 0.9953 - val_dice_coef: 0.6170\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.34943\n",
      "Epoch 11/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2517 - acc: 0.9969 - dice_coef: 0.7483 - val_loss: 0.4111 - val_acc: 0.9951 - val_dice_coef: 0.5889\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.34943\n",
      "Epoch 12/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2492 - acc: 0.9969 - dice_coef: 0.7508 - val_loss: 0.3840 - val_acc: 0.9952 - val_dice_coef: 0.6160\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.34943\n",
      "Epoch 13/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2494 - acc: 0.9969 - dice_coef: 0.7506 - val_loss: 0.3850 - val_acc: 0.9953 - val_dice_coef: 0.6150\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.34943\n",
      "Epoch 14/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2419 - acc: 0.9970 - dice_coef: 0.7581 - val_loss: 0.4124 - val_acc: 0.9948 - val_dice_coef: 0.5876\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.34943\n",
      "Epoch 15/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2388 - acc: 0.9970 - dice_coef: 0.7612 - val_loss: 0.3921 - val_acc: 0.9951 - val_dice_coef: 0.6079\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.34943\n",
      "Epoch 16/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2337 - acc: 0.9971 - dice_coef: 0.7663 - val_loss: 0.3951 - val_acc: 0.9952 - val_dice_coef: 0.6049\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.34943\n",
      "Epoch 17/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2322 - acc: 0.9971 - dice_coef: 0.7678 - val_loss: 0.3923 - val_acc: 0.9951 - val_dice_coef: 0.6077\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.34943\n",
      "Epoch 18/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2249 - acc: 0.9972 - dice_coef: 0.7751 - val_loss: 0.3920 - val_acc: 0.9951 - val_dice_coef: 0.6080\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.34943\n",
      "Epoch 19/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2252 - acc: 0.9972 - dice_coef: 0.7748 - val_loss: 0.3954 - val_acc: 0.9951 - val_dice_coef: 0.6046\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.34943\n",
      "Epoch 20/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2208 - acc: 0.9973 - dice_coef: 0.7792 - val_loss: 0.4169 - val_acc: 0.9948 - val_dice_coef: 0.5831\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.34943\n",
      "Epoch 21/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2252 - acc: 0.9973 - dice_coef: 0.7748 - val_loss: 0.4070 - val_acc: 0.9951 - val_dice_coef: 0.5930\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.34943\n",
      "Epoch 22/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2167 - acc: 0.9974 - dice_coef: 0.7833 - val_loss: 0.4009 - val_acc: 0.9951 - val_dice_coef: 0.5991\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.34943\n",
      "Epoch 23/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2092 - acc: 0.9974 - dice_coef: 0.7908 - val_loss: 0.4109 - val_acc: 0.9949 - val_dice_coef: 0.5891\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.34943\n",
      "Epoch 24/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2105 - acc: 0.9974 - dice_coef: 0.7895 - val_loss: 0.4141 - val_acc: 0.9950 - val_dice_coef: 0.5859\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.34943\n",
      "Epoch 25/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2049 - acc: 0.9974 - dice_coef: 0.7951 - val_loss: 0.4093 - val_acc: 0.9948 - val_dice_coef: 0.5907\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.34943\n",
      "Epoch 26/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2092 - acc: 0.9975 - dice_coef: 0.7908 - val_loss: 0.4068 - val_acc: 0.9949 - val_dice_coef: 0.5932\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.34943\n",
      "Epoch 27/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2039 - acc: 0.9975 - dice_coef: 0.7961 - val_loss: 0.4053 - val_acc: 0.9950 - val_dice_coef: 0.5947\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.34943\n",
      "Epoch 28/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2006 - acc: 0.9975 - dice_coef: 0.7994 - val_loss: 0.4217 - val_acc: 0.9946 - val_dice_coef: 0.5783\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.34943\n",
      "Epoch 29/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2048 - acc: 0.9975 - dice_coef: 0.7952 - val_loss: 0.4613 - val_acc: 0.9942 - val_dice_coef: 0.5387\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.34943\n",
      "Epoch 30/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2010 - acc: 0.9976 - dice_coef: 0.7990 - val_loss: 0.4208 - val_acc: 0.9946 - val_dice_coef: 0.5792\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.34943\n",
      "Train on 2115 samples, validate on 193 samples\n",
      "Epoch 1/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2121 - acc: 0.9974 - dice_coef: 0.7879 - val_loss: 0.3131 - val_acc: 0.9973 - val_dice_coef: 0.6869\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.31315, saving model to weights/weights-2crs-01ep-0.31loss.hdf5\n",
      "Epoch 2/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.2023 - acc: 0.9975 - dice_coef: 0.7977 - val_loss: 0.3183 - val_acc: 0.9973 - val_dice_coef: 0.6817\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31315\n",
      "Epoch 3/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1997 - acc: 0.9975 - dice_coef: 0.8003 - val_loss: 0.3135 - val_acc: 0.9974 - val_dice_coef: 0.6865\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31315\n",
      "Epoch 4/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1962 - acc: 0.9975 - dice_coef: 0.8038 - val_loss: 0.3162 - val_acc: 0.9974 - val_dice_coef: 0.6838\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31315\n",
      "Epoch 5/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1959 - acc: 0.9976 - dice_coef: 0.8041 - val_loss: 0.3220 - val_acc: 0.9973 - val_dice_coef: 0.6780\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31315\n",
      "Epoch 6/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1935 - acc: 0.9976 - dice_coef: 0.8065 - val_loss: 0.3125 - val_acc: 0.9974 - val_dice_coef: 0.6875\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.31315 to 0.31254, saving model to weights/weights-2crs-06ep-0.31loss.hdf5\n",
      "Epoch 7/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1905 - acc: 0.9976 - dice_coef: 0.8095 - val_loss: 0.3185 - val_acc: 0.9973 - val_dice_coef: 0.6815\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31254\n",
      "Epoch 8/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1894 - acc: 0.9977 - dice_coef: 0.8106 - val_loss: 0.3309 - val_acc: 0.9971 - val_dice_coef: 0.6691\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31254\n",
      "Epoch 9/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1812 - acc: 0.9977 - dice_coef: 0.8188 - val_loss: 0.3333 - val_acc: 0.9971 - val_dice_coef: 0.6667\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.31254\n",
      "Epoch 10/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1860 - acc: 0.9977 - dice_coef: 0.8140 - val_loss: 0.3276 - val_acc: 0.9972 - val_dice_coef: 0.6724\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.31254\n",
      "Epoch 11/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1826 - acc: 0.9978 - dice_coef: 0.8174 - val_loss: 0.3357 - val_acc: 0.9971 - val_dice_coef: 0.6643\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.31254\n",
      "Epoch 12/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1801 - acc: 0.9978 - dice_coef: 0.8199 - val_loss: 0.3170 - val_acc: 0.9973 - val_dice_coef: 0.6830\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.31254\n",
      "Epoch 13/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1759 - acc: 0.9978 - dice_coef: 0.8241 - val_loss: 0.3379 - val_acc: 0.9970 - val_dice_coef: 0.6621\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.31254\n",
      "Epoch 14/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1781 - acc: 0.9978 - dice_coef: 0.8219 - val_loss: 0.3412 - val_acc: 0.9970 - val_dice_coef: 0.6588\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.31254\n",
      "Epoch 15/30\n",
      "2115/2115 [==============================] - 270s 127ms/step - loss: 0.1765 - acc: 0.9978 - dice_coef: 0.8235 - val_loss: 0.3309 - val_acc: 0.9971 - val_dice_coef: 0.6691\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.31254\n",
      "Epoch 16/30\n",
      "2115/2115 [==============================] - 270s 127ms/step - loss: 0.1771 - acc: 0.9979 - dice_coef: 0.8229 - val_loss: 0.3336 - val_acc: 0.9971 - val_dice_coef: 0.6664\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.31254\n",
      "Epoch 17/30\n",
      "2115/2115 [==============================] - 270s 127ms/step - loss: 0.1705 - acc: 0.9979 - dice_coef: 0.8295 - val_loss: 0.3518 - val_acc: 0.9969 - val_dice_coef: 0.6482\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.31254\n",
      "Epoch 18/30\n",
      "2115/2115 [==============================] - 270s 128ms/step - loss: 0.1702 - acc: 0.9979 - dice_coef: 0.8298 - val_loss: 0.3368 - val_acc: 0.9970 - val_dice_coef: 0.6632\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.31254\n",
      "Epoch 19/30\n",
      "2115/2115 [==============================] - 270s 127ms/step - loss: 0.1712 - acc: 0.9979 - dice_coef: 0.8288 - val_loss: 0.3412 - val_acc: 0.9970 - val_dice_coef: 0.6588\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.31254\n",
      "Epoch 20/30\n",
      "2115/2115 [==============================] - 270s 128ms/step - loss: 0.1711 - acc: 0.9979 - dice_coef: 0.8289 - val_loss: 0.3535 - val_acc: 0.9968 - val_dice_coef: 0.6465\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.31254\n",
      "Epoch 21/30\n",
      "2115/2115 [==============================] - 270s 127ms/step - loss: 0.1656 - acc: 0.9980 - dice_coef: 0.8344 - val_loss: 0.3377 - val_acc: 0.9970 - val_dice_coef: 0.6623\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.31254\n",
      "Epoch 22/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1627 - acc: 0.9980 - dice_coef: 0.8373 - val_loss: 0.3493 - val_acc: 0.9968 - val_dice_coef: 0.6507\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.31254\n",
      "Epoch 23/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1614 - acc: 0.9980 - dice_coef: 0.8386 - val_loss: 0.3428 - val_acc: 0.9970 - val_dice_coef: 0.6572\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.31254\n",
      "Epoch 24/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1652 - acc: 0.9980 - dice_coef: 0.8348 - val_loss: 0.3503 - val_acc: 0.9969 - val_dice_coef: 0.6497\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.31254\n",
      "Epoch 25/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1630 - acc: 0.9980 - dice_coef: 0.8370 - val_loss: 0.3462 - val_acc: 0.9969 - val_dice_coef: 0.6538\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.31254\n",
      "Epoch 26/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1602 - acc: 0.9980 - dice_coef: 0.8398 - val_loss: 0.3463 - val_acc: 0.9969 - val_dice_coef: 0.6537\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.31254\n",
      "Epoch 27/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1568 - acc: 0.9981 - dice_coef: 0.8432 - val_loss: 0.3629 - val_acc: 0.9966 - val_dice_coef: 0.6371\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.31254\n",
      "Epoch 28/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1533 - acc: 0.9981 - dice_coef: 0.8467 - val_loss: 0.3561 - val_acc: 0.9968 - val_dice_coef: 0.6439\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.31254\n",
      "Epoch 29/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1596 - acc: 0.9981 - dice_coef: 0.8404 - val_loss: 0.3533 - val_acc: 0.9967 - val_dice_coef: 0.6467\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.31254\n",
      "Epoch 30/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1503 - acc: 0.9981 - dice_coef: 0.8497 - val_loss: 0.3663 - val_acc: 0.9967 - val_dice_coef: 0.6337\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.31254\n",
      "Train on 2115 samples, validate on 193 samples\n",
      "Epoch 1/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1631 - acc: 0.9980 - dice_coef: 0.8369 - val_loss: 0.2932 - val_acc: 0.9980 - val_dice_coef: 0.7068\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.29323, saving model to weights/weights-3crs-01ep-0.29loss.hdf5\n",
      "Epoch 2/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1554 - acc: 0.9981 - dice_coef: 0.8446 - val_loss: 0.2924 - val_acc: 0.9980 - val_dice_coef: 0.7076\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.29323 to 0.29237, saving model to weights/weights-3crs-02ep-0.29loss.hdf5\n",
      "Epoch 3/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1577 - acc: 0.9981 - dice_coef: 0.8423 - val_loss: 0.2929 - val_acc: 0.9980 - val_dice_coef: 0.7071\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.29237\n",
      "Epoch 4/30\n",
      "2115/2115 [==============================] - 270s 127ms/step - loss: 0.1523 - acc: 0.9981 - dice_coef: 0.8477 - val_loss: 0.2941 - val_acc: 0.9980 - val_dice_coef: 0.7059\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.29237\n",
      "Epoch 5/30\n",
      "2115/2115 [==============================] - 270s 127ms/step - loss: 0.1521 - acc: 0.9981 - dice_coef: 0.8479 - val_loss: 0.2943 - val_acc: 0.9980 - val_dice_coef: 0.7057\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.29237\n",
      "Epoch 6/30\n",
      "2115/2115 [==============================] - 270s 127ms/step - loss: 0.1549 - acc: 0.9981 - dice_coef: 0.8451 - val_loss: 0.2996 - val_acc: 0.9979 - val_dice_coef: 0.7004\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.29237\n",
      "Epoch 7/30\n",
      "2115/2115 [==============================] - 270s 127ms/step - loss: 0.1522 - acc: 0.9981 - dice_coef: 0.8478 - val_loss: 0.2980 - val_acc: 0.9979 - val_dice_coef: 0.7020\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.29237\n",
      "Epoch 8/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1457 - acc: 0.9982 - dice_coef: 0.8543 - val_loss: 0.2984 - val_acc: 0.9979 - val_dice_coef: 0.7016\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.29237\n",
      "Epoch 9/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1506 - acc: 0.9982 - dice_coef: 0.8494 - val_loss: 0.3030 - val_acc: 0.9979 - val_dice_coef: 0.6970\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.29237\n",
      "Epoch 10/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1459 - acc: 0.9982 - dice_coef: 0.8541 - val_loss: 0.3044 - val_acc: 0.9979 - val_dice_coef: 0.6956\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.29237\n",
      "Epoch 11/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1437 - acc: 0.9982 - dice_coef: 0.8563 - val_loss: 0.3039 - val_acc: 0.9979 - val_dice_coef: 0.6961\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.29237\n",
      "Epoch 12/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1431 - acc: 0.9982 - dice_coef: 0.8569 - val_loss: 0.3094 - val_acc: 0.9978 - val_dice_coef: 0.6906\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.29237\n",
      "Epoch 13/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1379 - acc: 0.9983 - dice_coef: 0.8621 - val_loss: 0.3067 - val_acc: 0.9978 - val_dice_coef: 0.6933\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.29237\n",
      "Epoch 14/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1403 - acc: 0.9983 - dice_coef: 0.8597 - val_loss: 0.2960 - val_acc: 0.9979 - val_dice_coef: 0.7040\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.29237\n",
      "Epoch 15/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1454 - acc: 0.9983 - dice_coef: 0.8546 - val_loss: 0.3051 - val_acc: 0.9978 - val_dice_coef: 0.6949\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.29237\n",
      "Epoch 16/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1379 - acc: 0.9983 - dice_coef: 0.8621 - val_loss: 0.3097 - val_acc: 0.9978 - val_dice_coef: 0.6903\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.29237\n",
      "Epoch 17/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1367 - acc: 0.9983 - dice_coef: 0.8633 - val_loss: 0.3261 - val_acc: 0.9976 - val_dice_coef: 0.6739\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.29237\n",
      "Epoch 18/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1388 - acc: 0.9983 - dice_coef: 0.8612 - val_loss: 0.3297 - val_acc: 0.9975 - val_dice_coef: 0.6703\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.29237\n",
      "Epoch 19/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1404 - acc: 0.9983 - dice_coef: 0.8596 - val_loss: 0.3028 - val_acc: 0.9979 - val_dice_coef: 0.6972\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.29237\n",
      "Epoch 20/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1374 - acc: 0.9983 - dice_coef: 0.8626 - val_loss: 0.3129 - val_acc: 0.9977 - val_dice_coef: 0.6871\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.29237\n",
      "Epoch 21/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1384 - acc: 0.9983 - dice_coef: 0.8616 - val_loss: 0.3008 - val_acc: 0.9979 - val_dice_coef: 0.6992\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.29237\n",
      "Epoch 22/30\n",
      "2115/2115 [==============================] - 270s 127ms/step - loss: 0.1376 - acc: 0.9983 - dice_coef: 0.8624 - val_loss: 0.3154 - val_acc: 0.9977 - val_dice_coef: 0.6846\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.29237\n",
      "Epoch 23/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1371 - acc: 0.9984 - dice_coef: 0.8629 - val_loss: 0.3109 - val_acc: 0.9978 - val_dice_coef: 0.6891\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.29237\n",
      "Epoch 24/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1344 - acc: 0.9984 - dice_coef: 0.8656 - val_loss: 0.3293 - val_acc: 0.9976 - val_dice_coef: 0.6707\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.29237\n",
      "Epoch 25/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1339 - acc: 0.9984 - dice_coef: 0.8661 - val_loss: 0.3115 - val_acc: 0.9978 - val_dice_coef: 0.6885\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.29237\n",
      "Epoch 26/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1313 - acc: 0.9984 - dice_coef: 0.8687 - val_loss: 0.3176 - val_acc: 0.9977 - val_dice_coef: 0.6824\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.29237\n",
      "Epoch 27/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1300 - acc: 0.9984 - dice_coef: 0.8700 - val_loss: 0.3070 - val_acc: 0.9978 - val_dice_coef: 0.6930\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.29237\n",
      "Epoch 28/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1258 - acc: 0.9984 - dice_coef: 0.8742 - val_loss: 0.3219 - val_acc: 0.9976 - val_dice_coef: 0.6781\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.29237\n",
      "Epoch 29/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1326 - acc: 0.9984 - dice_coef: 0.8674 - val_loss: 0.3134 - val_acc: 0.9977 - val_dice_coef: 0.6866\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.29237\n",
      "Epoch 30/30\n",
      "2115/2115 [==============================] - 269s 127ms/step - loss: 0.1266 - acc: 0.9984 - dice_coef: 0.8734 - val_loss: 0.3113 - val_acc: 0.9977 - val_dice_coef: 0.6887\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.29237\n",
      "Train on 2116 samples, validate on 192 samples\n",
      "Epoch 1/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1439 - acc: 0.9984 - dice_coef: 0.8561 - val_loss: 0.1863 - val_acc: 0.9984 - val_dice_coef: 0.8137\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18632, saving model to weights/weights-4crs-01ep-0.19loss.hdf5\n",
      "Epoch 2/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1364 - acc: 0.9984 - dice_coef: 0.8636 - val_loss: 0.1764 - val_acc: 0.9986 - val_dice_coef: 0.8236\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.18632 to 0.17642, saving model to weights/weights-4crs-02ep-0.18loss.hdf5\n",
      "Epoch 3/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1365 - acc: 0.9984 - dice_coef: 0.8635 - val_loss: 0.1806 - val_acc: 0.9985 - val_dice_coef: 0.8194\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.17642\n",
      "Epoch 4/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1291 - acc: 0.9984 - dice_coef: 0.8709 - val_loss: 0.1872 - val_acc: 0.9984 - val_dice_coef: 0.8128\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.17642\n",
      "Epoch 5/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.1359 - acc: 0.9984 - dice_coef: 0.8641 - val_loss: 0.1762 - val_acc: 0.9986 - val_dice_coef: 0.8238\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.17642 to 0.17618, saving model to weights/weights-4crs-05ep-0.18loss.hdf5\n",
      "Epoch 6/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.1320 - acc: 0.9984 - dice_coef: 0.8680 - val_loss: 0.1830 - val_acc: 0.9985 - val_dice_coef: 0.8170\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.17618\n",
      "Epoch 7/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.1320 - acc: 0.9984 - dice_coef: 0.8680 - val_loss: 0.1841 - val_acc: 0.9984 - val_dice_coef: 0.8159\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.17618\n",
      "Epoch 8/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.1298 - acc: 0.9984 - dice_coef: 0.8702 - val_loss: 0.1841 - val_acc: 0.9985 - val_dice_coef: 0.8159\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.17618\n",
      "Epoch 9/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1282 - acc: 0.9984 - dice_coef: 0.8718 - val_loss: 0.1866 - val_acc: 0.9984 - val_dice_coef: 0.8134\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.17618\n",
      "Epoch 10/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1313 - acc: 0.9985 - dice_coef: 0.8687 - val_loss: 0.1969 - val_acc: 0.9983 - val_dice_coef: 0.8031\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.17618\n",
      "Epoch 11/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1276 - acc: 0.9985 - dice_coef: 0.8724 - val_loss: 0.1824 - val_acc: 0.9985 - val_dice_coef: 0.8176\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.17618\n",
      "Epoch 12/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1320 - acc: 0.9985 - dice_coef: 0.8680 - val_loss: 0.1935 - val_acc: 0.9983 - val_dice_coef: 0.8065\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.17618\n",
      "Epoch 13/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1327 - acc: 0.9984 - dice_coef: 0.8673 - val_loss: 0.1880 - val_acc: 0.9984 - val_dice_coef: 0.8120\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.17618\n",
      "Epoch 14/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1278 - acc: 0.9985 - dice_coef: 0.8722 - val_loss: 0.1916 - val_acc: 0.9983 - val_dice_coef: 0.8084\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.17618\n",
      "Epoch 15/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1238 - acc: 0.9985 - dice_coef: 0.8762 - val_loss: 0.1926 - val_acc: 0.9984 - val_dice_coef: 0.8074\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.17618\n",
      "Epoch 16/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1266 - acc: 0.9985 - dice_coef: 0.8734 - val_loss: 0.1927 - val_acc: 0.9983 - val_dice_coef: 0.8073\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.17618\n",
      "Epoch 17/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1287 - acc: 0.9985 - dice_coef: 0.8713 - val_loss: 0.1937 - val_acc: 0.9983 - val_dice_coef: 0.8063\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.17618\n",
      "Epoch 18/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1245 - acc: 0.9985 - dice_coef: 0.8755 - val_loss: 0.1951 - val_acc: 0.9983 - val_dice_coef: 0.8049\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.17618\n",
      "Epoch 19/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.1274 - acc: 0.9985 - dice_coef: 0.8726 - val_loss: 0.1894 - val_acc: 0.9984 - val_dice_coef: 0.8106\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.17618\n",
      "Epoch 20/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.1190 - acc: 0.9986 - dice_coef: 0.8810 - val_loss: 0.1960 - val_acc: 0.9983 - val_dice_coef: 0.8040\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.17618\n",
      "Epoch 21/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1185 - acc: 0.9986 - dice_coef: 0.8815 - val_loss: 0.1922 - val_acc: 0.9983 - val_dice_coef: 0.8078\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.17618\n",
      "Epoch 22/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1232 - acc: 0.9986 - dice_coef: 0.8768 - val_loss: 0.1988 - val_acc: 0.9983 - val_dice_coef: 0.8012\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.17618\n",
      "Epoch 23/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1271 - acc: 0.9986 - dice_coef: 0.8729 - val_loss: 0.1968 - val_acc: 0.9983 - val_dice_coef: 0.8032\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.17618\n",
      "Epoch 24/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1187 - acc: 0.9986 - dice_coef: 0.8813 - val_loss: 0.2002 - val_acc: 0.9982 - val_dice_coef: 0.7998\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.17618\n",
      "Epoch 25/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1225 - acc: 0.9986 - dice_coef: 0.8775 - val_loss: 0.1978 - val_acc: 0.9983 - val_dice_coef: 0.8022\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.17618\n",
      "Epoch 26/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1187 - acc: 0.9986 - dice_coef: 0.8813 - val_loss: 0.2011 - val_acc: 0.9982 - val_dice_coef: 0.7989\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.17618\n",
      "Epoch 27/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1205 - acc: 0.9986 - dice_coef: 0.8795 - val_loss: 0.2020 - val_acc: 0.9982 - val_dice_coef: 0.7980\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.17618\n",
      "Epoch 28/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1180 - acc: 0.9986 - dice_coef: 0.8820 - val_loss: 0.2040 - val_acc: 0.9982 - val_dice_coef: 0.7960\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.17618\n",
      "Epoch 29/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1175 - acc: 0.9986 - dice_coef: 0.8825 - val_loss: 0.2003 - val_acc: 0.9983 - val_dice_coef: 0.7997\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.17618\n",
      "Epoch 30/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1117 - acc: 0.9986 - dice_coef: 0.8883 - val_loss: 0.2035 - val_acc: 0.9982 - val_dice_coef: 0.7965\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.17618\n",
      "Train on 2116 samples, validate on 192 samples\n",
      "Epoch 1/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1207 - acc: 0.9986 - dice_coef: 0.8793 - val_loss: 0.2041 - val_acc: 0.9987 - val_dice_coef: 0.7959\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20407, saving model to weights/weights-5crs-01ep-0.20loss.hdf5\n",
      "Epoch 2/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1141 - acc: 0.9986 - dice_coef: 0.8859 - val_loss: 0.2077 - val_acc: 0.9987 - val_dice_coef: 0.7923\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.20407\n",
      "Epoch 3/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.1155 - acc: 0.9986 - dice_coef: 0.8845 - val_loss: 0.2056 - val_acc: 0.9987 - val_dice_coef: 0.7944\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.20407\n",
      "Epoch 4/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.1069 - acc: 0.9986 - dice_coef: 0.8931 - val_loss: 0.2016 - val_acc: 0.9987 - val_dice_coef: 0.7984\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.20407 to 0.20156, saving model to weights/weights-5crs-04ep-0.20loss.hdf5\n",
      "Epoch 5/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.1115 - acc: 0.9986 - dice_coef: 0.8885 - val_loss: 0.2038 - val_acc: 0.9987 - val_dice_coef: 0.7962\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.20156\n",
      "Epoch 6/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.1147 - acc: 0.9986 - dice_coef: 0.8853 - val_loss: 0.2064 - val_acc: 0.9987 - val_dice_coef: 0.7936\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.20156\n",
      "Epoch 7/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1110 - acc: 0.9986 - dice_coef: 0.8890 - val_loss: 0.2064 - val_acc: 0.9987 - val_dice_coef: 0.7936\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.20156\n",
      "Epoch 8/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1159 - acc: 0.9986 - dice_coef: 0.8841 - val_loss: 0.2049 - val_acc: 0.9987 - val_dice_coef: 0.7951\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.20156\n",
      "Epoch 9/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1151 - acc: 0.9987 - dice_coef: 0.8849 - val_loss: 0.2057 - val_acc: 0.9987 - val_dice_coef: 0.7943\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.20156\n",
      "Epoch 10/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1115 - acc: 0.9987 - dice_coef: 0.8885 - val_loss: 0.2071 - val_acc: 0.9987 - val_dice_coef: 0.7929\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.20156\n",
      "Epoch 11/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1070 - acc: 0.9987 - dice_coef: 0.8930 - val_loss: 0.2109 - val_acc: 0.9986 - val_dice_coef: 0.7891\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.20156\n",
      "Epoch 12/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1118 - acc: 0.9987 - dice_coef: 0.8882 - val_loss: 0.2097 - val_acc: 0.9986 - val_dice_coef: 0.7903\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.20156\n",
      "Epoch 13/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1102 - acc: 0.9987 - dice_coef: 0.8898 - val_loss: 0.2149 - val_acc: 0.9986 - val_dice_coef: 0.7851\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.20156\n",
      "Epoch 14/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1075 - acc: 0.9987 - dice_coef: 0.8925 - val_loss: 0.2072 - val_acc: 0.9987 - val_dice_coef: 0.7928\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.20156\n",
      "Epoch 15/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1063 - acc: 0.9987 - dice_coef: 0.8937 - val_loss: 0.2152 - val_acc: 0.9986 - val_dice_coef: 0.7848\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.20156\n",
      "Epoch 16/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1097 - acc: 0.9987 - dice_coef: 0.8903 - val_loss: 0.2131 - val_acc: 0.9986 - val_dice_coef: 0.7869\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.20156\n",
      "Epoch 17/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.1050 - acc: 0.9987 - dice_coef: 0.8950 - val_loss: 0.2122 - val_acc: 0.9986 - val_dice_coef: 0.7878\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.20156\n",
      "Epoch 18/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.1070 - acc: 0.9987 - dice_coef: 0.8930 - val_loss: 0.2262 - val_acc: 0.9985 - val_dice_coef: 0.7738\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.20156\n",
      "Epoch 19/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.1079 - acc: 0.9987 - dice_coef: 0.8921 - val_loss: 0.2106 - val_acc: 0.9986 - val_dice_coef: 0.7894\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.20156\n",
      "Epoch 20/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.1047 - acc: 0.9987 - dice_coef: 0.8953 - val_loss: 0.2128 - val_acc: 0.9986 - val_dice_coef: 0.7872\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.20156\n",
      "Epoch 21/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.1060 - acc: 0.9987 - dice_coef: 0.8940 - val_loss: 0.2111 - val_acc: 0.9986 - val_dice_coef: 0.7889\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.20156\n",
      "Epoch 22/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1058 - acc: 0.9987 - dice_coef: 0.8942 - val_loss: 0.2169 - val_acc: 0.9986 - val_dice_coef: 0.7831\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.20156\n",
      "Epoch 23/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1066 - acc: 0.9988 - dice_coef: 0.8934 - val_loss: 0.2148 - val_acc: 0.9986 - val_dice_coef: 0.7852\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.20156\n",
      "Epoch 24/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1095 - acc: 0.9987 - dice_coef: 0.8905 - val_loss: 0.2181 - val_acc: 0.9985 - val_dice_coef: 0.7819\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.20156\n",
      "Epoch 25/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1072 - acc: 0.9988 - dice_coef: 0.8928 - val_loss: 0.2243 - val_acc: 0.9985 - val_dice_coef: 0.7757\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.20156\n",
      "Epoch 26/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1018 - acc: 0.9988 - dice_coef: 0.8982 - val_loss: 0.2181 - val_acc: 0.9985 - val_dice_coef: 0.7819\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.20156\n",
      "Epoch 27/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1019 - acc: 0.9988 - dice_coef: 0.8981 - val_loss: 0.2222 - val_acc: 0.9985 - val_dice_coef: 0.7778\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.20156\n",
      "Epoch 28/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1031 - acc: 0.9988 - dice_coef: 0.8969 - val_loss: 0.2164 - val_acc: 0.9985 - val_dice_coef: 0.7836\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.20156\n",
      "Epoch 29/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1000 - acc: 0.9988 - dice_coef: 0.9000 - val_loss: 0.2268 - val_acc: 0.9984 - val_dice_coef: 0.7732\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.20156\n",
      "Epoch 30/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0988 - acc: 0.9988 - dice_coef: 0.9012 - val_loss: 0.2174 - val_acc: 0.9985 - val_dice_coef: 0.7826\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.20156\n",
      "Train on 2116 samples, validate on 192 samples\n",
      "Epoch 1/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1077 - acc: 0.9988 - dice_coef: 0.8923 - val_loss: 0.1139 - val_acc: 0.9989 - val_dice_coef: 0.8861\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11387, saving model to weights/weights-6crs-01ep-0.11loss.hdf5\n",
      "Epoch 2/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.1040 - acc: 0.9988 - dice_coef: 0.8960 - val_loss: 0.1141 - val_acc: 0.9989 - val_dice_coef: 0.8859\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11387\n",
      "Epoch 3/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.1032 - acc: 0.9988 - dice_coef: 0.8968 - val_loss: 0.1150 - val_acc: 0.9988 - val_dice_coef: 0.8850\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11387\n",
      "Epoch 4/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.1070 - acc: 0.9988 - dice_coef: 0.8930 - val_loss: 0.1149 - val_acc: 0.9989 - val_dice_coef: 0.8851\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.11387\n",
      "Epoch 5/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.1069 - acc: 0.9988 - dice_coef: 0.8931 - val_loss: 0.1170 - val_acc: 0.9988 - val_dice_coef: 0.8830\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.11387\n",
      "Epoch 6/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.1033 - acc: 0.9988 - dice_coef: 0.8967 - val_loss: 0.1186 - val_acc: 0.9988 - val_dice_coef: 0.8814\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.11387\n",
      "Epoch 7/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.1024 - acc: 0.9988 - dice_coef: 0.8976 - val_loss: 0.1153 - val_acc: 0.9989 - val_dice_coef: 0.8847\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.11387\n",
      "Epoch 8/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.1066 - acc: 0.9988 - dice_coef: 0.8934 - val_loss: 0.1208 - val_acc: 0.9988 - val_dice_coef: 0.8792\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.11387\n",
      "Epoch 9/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.0941 - acc: 0.9988 - dice_coef: 0.9059 - val_loss: 0.1174 - val_acc: 0.9988 - val_dice_coef: 0.8826\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.11387\n",
      "Epoch 10/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1130 - acc: 0.9988 - dice_coef: 0.8870 - val_loss: 0.1186 - val_acc: 0.9988 - val_dice_coef: 0.8814\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.11387\n",
      "Epoch 11/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1050 - acc: 0.9988 - dice_coef: 0.8950 - val_loss: 0.1325 - val_acc: 0.9987 - val_dice_coef: 0.8675\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.11387\n",
      "Epoch 12/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1077 - acc: 0.9988 - dice_coef: 0.8923 - val_loss: 0.1193 - val_acc: 0.9988 - val_dice_coef: 0.8807\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.11387\n",
      "Epoch 13/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1063 - acc: 0.9989 - dice_coef: 0.8937 - val_loss: 0.1178 - val_acc: 0.9988 - val_dice_coef: 0.8822\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.11387\n",
      "Epoch 14/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0960 - acc: 0.9989 - dice_coef: 0.9040 - val_loss: 0.1191 - val_acc: 0.9988 - val_dice_coef: 0.8809\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.11387\n",
      "Epoch 15/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.1058 - acc: 0.9989 - dice_coef: 0.8942 - val_loss: 0.1336 - val_acc: 0.9986 - val_dice_coef: 0.8664\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.11387\n",
      "Epoch 16/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0987 - acc: 0.9988 - dice_coef: 0.9013 - val_loss: 0.1220 - val_acc: 0.9988 - val_dice_coef: 0.8780\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.11387\n",
      "Epoch 17/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0947 - acc: 0.9989 - dice_coef: 0.9053 - val_loss: 0.1195 - val_acc: 0.9988 - val_dice_coef: 0.8805\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.11387\n",
      "Epoch 18/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0975 - acc: 0.9989 - dice_coef: 0.9025 - val_loss: 0.1203 - val_acc: 0.9988 - val_dice_coef: 0.8797\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.11387\n",
      "Epoch 19/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0952 - acc: 0.9989 - dice_coef: 0.9048 - val_loss: 0.1233 - val_acc: 0.9988 - val_dice_coef: 0.8767\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.11387\n",
      "Epoch 20/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0975 - acc: 0.9989 - dice_coef: 0.9025 - val_loss: 0.1258 - val_acc: 0.9987 - val_dice_coef: 0.8742\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.11387\n",
      "Epoch 21/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0939 - acc: 0.9989 - dice_coef: 0.9061 - val_loss: 0.1240 - val_acc: 0.9987 - val_dice_coef: 0.8760\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.11387\n",
      "Epoch 22/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0975 - acc: 0.9989 - dice_coef: 0.9025 - val_loss: 0.1288 - val_acc: 0.9987 - val_dice_coef: 0.8712\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.11387\n",
      "Epoch 23/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.0929 - acc: 0.9989 - dice_coef: 0.9071 - val_loss: 0.1192 - val_acc: 0.9988 - val_dice_coef: 0.8808\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.11387\n",
      "Epoch 24/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.0999 - acc: 0.9989 - dice_coef: 0.9001 - val_loss: 0.1259 - val_acc: 0.9987 - val_dice_coef: 0.8741\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.11387\n",
      "Epoch 25/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.1018 - acc: 0.9989 - dice_coef: 0.8982 - val_loss: 0.1273 - val_acc: 0.9987 - val_dice_coef: 0.8727\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.11387\n",
      "Epoch 26/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0977 - acc: 0.9989 - dice_coef: 0.9023 - val_loss: 0.1239 - val_acc: 0.9987 - val_dice_coef: 0.8761\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.11387\n",
      "Epoch 27/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0924 - acc: 0.9989 - dice_coef: 0.9076 - val_loss: 0.1283 - val_acc: 0.9987 - val_dice_coef: 0.8717\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.11387\n",
      "Epoch 28/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0993 - acc: 0.9989 - dice_coef: 0.9007 - val_loss: 0.1250 - val_acc: 0.9987 - val_dice_coef: 0.8750\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.11387\n",
      "Epoch 29/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0979 - acc: 0.9989 - dice_coef: 0.9021 - val_loss: 0.1296 - val_acc: 0.9987 - val_dice_coef: 0.8704\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.11387\n",
      "Epoch 30/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0955 - acc: 0.9989 - dice_coef: 0.9045 - val_loss: 0.1309 - val_acc: 0.9987 - val_dice_coef: 0.8691\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.11387\n",
      "Train on 2116 samples, validate on 192 samples\n",
      "Epoch 1/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0977 - acc: 0.9989 - dice_coef: 0.9023 - val_loss: 0.1602 - val_acc: 0.9987 - val_dice_coef: 0.8398\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16015, saving model to weights/weights-7crs-01ep-0.16loss.hdf5\n",
      "Epoch 2/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0977 - acc: 0.9989 - dice_coef: 0.9023 - val_loss: 0.1611 - val_acc: 0.9987 - val_dice_coef: 0.8389\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.16015\n",
      "Epoch 3/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0978 - acc: 0.9989 - dice_coef: 0.9022 - val_loss: 0.1620 - val_acc: 0.9986 - val_dice_coef: 0.8380\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16015\n",
      "Epoch 4/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0954 - acc: 0.9989 - dice_coef: 0.9046 - val_loss: 0.1687 - val_acc: 0.9985 - val_dice_coef: 0.8313\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.16015\n",
      "Epoch 5/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0961 - acc: 0.9989 - dice_coef: 0.9039 - val_loss: 0.1632 - val_acc: 0.9986 - val_dice_coef: 0.8368\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.16015\n",
      "Epoch 6/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0942 - acc: 0.9990 - dice_coef: 0.9058 - val_loss: 0.1639 - val_acc: 0.9986 - val_dice_coef: 0.8361\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.16015\n",
      "Epoch 7/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0910 - acc: 0.9990 - dice_coef: 0.9090 - val_loss: 0.1614 - val_acc: 0.9986 - val_dice_coef: 0.8386\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.16015\n",
      "Epoch 8/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0936 - acc: 0.9990 - dice_coef: 0.9064 - val_loss: 0.1658 - val_acc: 0.9986 - val_dice_coef: 0.8342\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.16015\n",
      "Epoch 9/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.0929 - acc: 0.9990 - dice_coef: 0.9071 - val_loss: 0.1630 - val_acc: 0.9986 - val_dice_coef: 0.8370\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.16015\n",
      "Epoch 10/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.0928 - acc: 0.9990 - dice_coef: 0.9072 - val_loss: 0.1641 - val_acc: 0.9986 - val_dice_coef: 0.8359\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.16015\n",
      "Epoch 11/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0906 - acc: 0.9990 - dice_coef: 0.9094 - val_loss: 0.1630 - val_acc: 0.9986 - val_dice_coef: 0.8370\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.16015\n",
      "Epoch 12/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0972 - acc: 0.9990 - dice_coef: 0.9028 - val_loss: 0.1775 - val_acc: 0.9983 - val_dice_coef: 0.8225\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.16015\n",
      "Epoch 13/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0881 - acc: 0.9990 - dice_coef: 0.9119 - val_loss: 0.1725 - val_acc: 0.9984 - val_dice_coef: 0.8275\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.16015\n",
      "Epoch 14/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0900 - acc: 0.9990 - dice_coef: 0.9100 - val_loss: 0.1708 - val_acc: 0.9985 - val_dice_coef: 0.8292\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.16015\n",
      "Epoch 15/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0872 - acc: 0.9990 - dice_coef: 0.9128 - val_loss: 0.1774 - val_acc: 0.9983 - val_dice_coef: 0.8226\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.16015\n",
      "Epoch 16/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0898 - acc: 0.9990 - dice_coef: 0.9102 - val_loss: 0.1761 - val_acc: 0.9984 - val_dice_coef: 0.8239\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.16015\n",
      "Epoch 17/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0912 - acc: 0.9990 - dice_coef: 0.9088 - val_loss: 0.1727 - val_acc: 0.9984 - val_dice_coef: 0.8273\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.16015\n",
      "Epoch 18/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0836 - acc: 0.9990 - dice_coef: 0.9164 - val_loss: 0.1710 - val_acc: 0.9985 - val_dice_coef: 0.8290\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.16015\n",
      "Epoch 19/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0965 - acc: 0.9990 - dice_coef: 0.9035 - val_loss: 0.1730 - val_acc: 0.9984 - val_dice_coef: 0.8270\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.16015\n",
      "Epoch 20/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0885 - acc: 0.9990 - dice_coef: 0.9115 - val_loss: 0.1722 - val_acc: 0.9984 - val_dice_coef: 0.8278\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.16015\n",
      "Epoch 21/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0924 - acc: 0.9990 - dice_coef: 0.9076 - val_loss: 0.1803 - val_acc: 0.9983 - val_dice_coef: 0.8197\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.16015\n",
      "Epoch 22/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0905 - acc: 0.9990 - dice_coef: 0.9095 - val_loss: 0.1755 - val_acc: 0.9984 - val_dice_coef: 0.8245\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.16015\n",
      "Epoch 23/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0912 - acc: 0.9990 - dice_coef: 0.9088 - val_loss: 0.1718 - val_acc: 0.9985 - val_dice_coef: 0.8282\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.16015\n",
      "Epoch 24/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0867 - acc: 0.9990 - dice_coef: 0.9133 - val_loss: 0.1763 - val_acc: 0.9984 - val_dice_coef: 0.8237\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.16015\n",
      "Epoch 25/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0910 - acc: 0.9990 - dice_coef: 0.9090 - val_loss: 0.1776 - val_acc: 0.9984 - val_dice_coef: 0.8224\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.16015\n",
      "Epoch 26/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0861 - acc: 0.9990 - dice_coef: 0.9139 - val_loss: 0.1766 - val_acc: 0.9984 - val_dice_coef: 0.8234\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.16015\n",
      "Epoch 27/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0851 - acc: 0.9990 - dice_coef: 0.9149 - val_loss: 0.1725 - val_acc: 0.9984 - val_dice_coef: 0.8275\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.16015\n",
      "Epoch 28/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0906 - acc: 0.9990 - dice_coef: 0.9094 - val_loss: 0.1749 - val_acc: 0.9984 - val_dice_coef: 0.8251\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.16015\n",
      "Epoch 29/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0847 - acc: 0.9990 - dice_coef: 0.9153 - val_loss: 0.1763 - val_acc: 0.9984 - val_dice_coef: 0.8237\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.16015\n",
      "Epoch 30/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0838 - acc: 0.9990 - dice_coef: 0.9162 - val_loss: 0.1833 - val_acc: 0.9983 - val_dice_coef: 0.8167\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.16015\n",
      "Train on 2116 samples, validate on 192 samples\n",
      "Epoch 1/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0847 - acc: 0.9990 - dice_coef: 0.9153 - val_loss: 0.2244 - val_acc: 0.9990 - val_dice_coef: 0.7756\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.22443, saving model to weights/weights-8crs-01ep-0.22loss.hdf5\n",
      "Epoch 2/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0932 - acc: 0.9990 - dice_coef: 0.9068 - val_loss: 0.2270 - val_acc: 0.9989 - val_dice_coef: 0.7730\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.22443\n",
      "Epoch 3/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0844 - acc: 0.9990 - dice_coef: 0.9156 - val_loss: 0.2233 - val_acc: 0.9990 - val_dice_coef: 0.7767\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.22443 to 0.22327, saving model to weights/weights-8crs-03ep-0.22loss.hdf5\n",
      "Epoch 4/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0875 - acc: 0.9990 - dice_coef: 0.9125 - val_loss: 0.2247 - val_acc: 0.9989 - val_dice_coef: 0.7753\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.22327\n",
      "Epoch 5/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0832 - acc: 0.9990 - dice_coef: 0.9168 - val_loss: 0.2239 - val_acc: 0.9990 - val_dice_coef: 0.7761\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.22327\n",
      "Epoch 6/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0853 - acc: 0.9990 - dice_coef: 0.9147 - val_loss: 0.2250 - val_acc: 0.9989 - val_dice_coef: 0.7750\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.22327\n",
      "Epoch 7/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0887 - acc: 0.9990 - dice_coef: 0.9113 - val_loss: 0.2327 - val_acc: 0.9988 - val_dice_coef: 0.7673\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.22327\n",
      "Epoch 8/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0815 - acc: 0.9990 - dice_coef: 0.9185 - val_loss: 0.2237 - val_acc: 0.9990 - val_dice_coef: 0.7763\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.22327\n",
      "Epoch 9/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0803 - acc: 0.9990 - dice_coef: 0.9197 - val_loss: 0.2258 - val_acc: 0.9989 - val_dice_coef: 0.7742\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.22327\n",
      "Epoch 10/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.0827 - acc: 0.9991 - dice_coef: 0.9173 - val_loss: 0.2283 - val_acc: 0.9989 - val_dice_coef: 0.7717\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.22327\n",
      "Epoch 11/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.0903 - acc: 0.9991 - dice_coef: 0.9097 - val_loss: 0.2263 - val_acc: 0.9989 - val_dice_coef: 0.7737\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.22327\n",
      "Epoch 12/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0866 - acc: 0.9991 - dice_coef: 0.9134 - val_loss: 0.2317 - val_acc: 0.9988 - val_dice_coef: 0.7683\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.22327\n",
      "Epoch 13/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0801 - acc: 0.9991 - dice_coef: 0.9199 - val_loss: 0.2315 - val_acc: 0.9988 - val_dice_coef: 0.7685\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.22327\n",
      "Epoch 14/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0849 - acc: 0.9991 - dice_coef: 0.9151 - val_loss: 0.2267 - val_acc: 0.9989 - val_dice_coef: 0.7733\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.22327\n",
      "Epoch 15/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0824 - acc: 0.9991 - dice_coef: 0.9176 - val_loss: 0.2292 - val_acc: 0.9989 - val_dice_coef: 0.7708\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.22327\n",
      "Epoch 16/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0847 - acc: 0.9991 - dice_coef: 0.9153 - val_loss: 0.2307 - val_acc: 0.9988 - val_dice_coef: 0.7693\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.22327\n",
      "Epoch 17/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0776 - acc: 0.9991 - dice_coef: 0.9224 - val_loss: 0.2291 - val_acc: 0.9989 - val_dice_coef: 0.7709\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.22327\n",
      "Epoch 18/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0803 - acc: 0.9991 - dice_coef: 0.9197 - val_loss: 0.2274 - val_acc: 0.9989 - val_dice_coef: 0.7726\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.22327\n",
      "Epoch 19/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0839 - acc: 0.9991 - dice_coef: 0.9161 - val_loss: 0.2287 - val_acc: 0.9989 - val_dice_coef: 0.7713\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.22327\n",
      "Epoch 20/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0756 - acc: 0.9991 - dice_coef: 0.9244 - val_loss: 0.2340 - val_acc: 0.9988 - val_dice_coef: 0.7660\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.22327\n",
      "Epoch 21/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0776 - acc: 0.9991 - dice_coef: 0.9224 - val_loss: 0.2309 - val_acc: 0.9988 - val_dice_coef: 0.7691\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.22327\n",
      "Epoch 22/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0782 - acc: 0.9991 - dice_coef: 0.9218 - val_loss: 0.2315 - val_acc: 0.9988 - val_dice_coef: 0.7685\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.22327\n",
      "Epoch 23/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0803 - acc: 0.9991 - dice_coef: 0.9197 - val_loss: 0.2307 - val_acc: 0.9988 - val_dice_coef: 0.7693\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.22327\n",
      "Epoch 24/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0865 - acc: 0.9991 - dice_coef: 0.9135 - val_loss: 0.2321 - val_acc: 0.9988 - val_dice_coef: 0.7679\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.22327\n",
      "Epoch 25/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0802 - acc: 0.9991 - dice_coef: 0.9198 - val_loss: 0.2306 - val_acc: 0.9988 - val_dice_coef: 0.7694\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.22327\n",
      "Epoch 26/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0827 - acc: 0.9991 - dice_coef: 0.9173 - val_loss: 0.2311 - val_acc: 0.9988 - val_dice_coef: 0.7689\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.22327\n",
      "Epoch 27/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0826 - acc: 0.9991 - dice_coef: 0.9174 - val_loss: 0.2555 - val_acc: 0.9984 - val_dice_coef: 0.7445\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.22327\n",
      "Epoch 28/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0776 - acc: 0.9991 - dice_coef: 0.9224 - val_loss: 0.2486 - val_acc: 0.9985 - val_dice_coef: 0.7514\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.22327\n",
      "Epoch 29/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0800 - acc: 0.9991 - dice_coef: 0.9200 - val_loss: 0.2324 - val_acc: 0.9988 - val_dice_coef: 0.7676\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.22327\n",
      "Epoch 30/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0784 - acc: 0.9991 - dice_coef: 0.9216 - val_loss: 0.2372 - val_acc: 0.9987 - val_dice_coef: 0.7628\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.22327\n",
      "Train on 2116 samples, validate on 192 samples\n",
      "Epoch 1/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0796 - acc: 0.9991 - dice_coef: 0.9204 - val_loss: 0.2252 - val_acc: 0.9983 - val_dice_coef: 0.7748\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.22523, saving model to weights/weights-9crs-01ep-0.23loss.hdf5\n",
      "Epoch 2/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0807 - acc: 0.9991 - dice_coef: 0.9193 - val_loss: 0.2201 - val_acc: 0.9985 - val_dice_coef: 0.7799\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.22523 to 0.22008, saving model to weights/weights-9crs-02ep-0.22loss.hdf5\n",
      "Epoch 3/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0841 - acc: 0.9991 - dice_coef: 0.9159 - val_loss: 0.2198 - val_acc: 0.9985 - val_dice_coef: 0.7802\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.22008 to 0.21979, saving model to weights/weights-9crs-03ep-0.22loss.hdf5\n",
      "Epoch 4/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0813 - acc: 0.9991 - dice_coef: 0.9187 - val_loss: 0.2189 - val_acc: 0.9985 - val_dice_coef: 0.7811\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.21979 to 0.21891, saving model to weights/weights-9crs-04ep-0.22loss.hdf5\n",
      "Epoch 5/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0789 - acc: 0.9991 - dice_coef: 0.9211 - val_loss: 0.2203 - val_acc: 0.9985 - val_dice_coef: 0.7797\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.21891\n",
      "Epoch 6/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0782 - acc: 0.9991 - dice_coef: 0.9218 - val_loss: 0.2220 - val_acc: 0.9984 - val_dice_coef: 0.7780\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.21891\n",
      "Epoch 7/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0816 - acc: 0.9991 - dice_coef: 0.9184 - val_loss: 0.2221 - val_acc: 0.9984 - val_dice_coef: 0.7779\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.21891\n",
      "Epoch 8/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0787 - acc: 0.9991 - dice_coef: 0.9213 - val_loss: 0.2226 - val_acc: 0.9984 - val_dice_coef: 0.7774\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.21891\n",
      "Epoch 9/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0818 - acc: 0.9992 - dice_coef: 0.9182 - val_loss: 0.2198 - val_acc: 0.9985 - val_dice_coef: 0.7802\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.21891\n",
      "Epoch 10/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0756 - acc: 0.9992 - dice_coef: 0.9244 - val_loss: 0.2259 - val_acc: 0.9983 - val_dice_coef: 0.7741\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.21891\n",
      "Epoch 11/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0827 - acc: 0.9992 - dice_coef: 0.9173 - val_loss: 0.2335 - val_acc: 0.9982 - val_dice_coef: 0.7665\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.21891\n",
      "Epoch 12/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0747 - acc: 0.9992 - dice_coef: 0.9253 - val_loss: 0.2258 - val_acc: 0.9984 - val_dice_coef: 0.7742\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.21891\n",
      "Epoch 13/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0774 - acc: 0.9992 - dice_coef: 0.9226 - val_loss: 0.2253 - val_acc: 0.9984 - val_dice_coef: 0.7747\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.21891\n",
      "Epoch 14/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0803 - acc: 0.9992 - dice_coef: 0.9197 - val_loss: 0.2299 - val_acc: 0.9983 - val_dice_coef: 0.7701\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.21891\n",
      "Epoch 15/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0714 - acc: 0.9992 - dice_coef: 0.9286 - val_loss: 0.2350 - val_acc: 0.9981 - val_dice_coef: 0.7650\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.21891\n",
      "Epoch 16/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0765 - acc: 0.9992 - dice_coef: 0.9235 - val_loss: 0.2307 - val_acc: 0.9982 - val_dice_coef: 0.7693\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.21891\n",
      "Epoch 17/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0755 - acc: 0.9992 - dice_coef: 0.9245 - val_loss: 0.2285 - val_acc: 0.9983 - val_dice_coef: 0.7715\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.21891\n",
      "Epoch 18/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0739 - acc: 0.9992 - dice_coef: 0.9261 - val_loss: 0.2298 - val_acc: 0.9982 - val_dice_coef: 0.7702\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.21891\n",
      "Epoch 19/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0809 - acc: 0.9992 - dice_coef: 0.9191 - val_loss: 0.2273 - val_acc: 0.9983 - val_dice_coef: 0.7727\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.21891\n",
      "Epoch 20/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0819 - acc: 0.9992 - dice_coef: 0.9181 - val_loss: 0.2319 - val_acc: 0.9982 - val_dice_coef: 0.7681\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.21891\n",
      "Epoch 21/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0710 - acc: 0.9992 - dice_coef: 0.9290 - val_loss: 0.2269 - val_acc: 0.9983 - val_dice_coef: 0.7731\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.21891\n",
      "Epoch 22/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0750 - acc: 0.9992 - dice_coef: 0.9250 - val_loss: 0.2294 - val_acc: 0.9983 - val_dice_coef: 0.7706\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.21891\n",
      "Epoch 23/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0727 - acc: 0.9992 - dice_coef: 0.9273 - val_loss: 0.2340 - val_acc: 0.9982 - val_dice_coef: 0.7660\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.21891\n",
      "Epoch 24/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0750 - acc: 0.9992 - dice_coef: 0.9250 - val_loss: 0.2332 - val_acc: 0.9981 - val_dice_coef: 0.7668\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.21891\n",
      "Epoch 25/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0754 - acc: 0.9992 - dice_coef: 0.9246 - val_loss: 0.2370 - val_acc: 0.9981 - val_dice_coef: 0.7630\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.21891\n",
      "Epoch 26/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0700 - acc: 0.9992 - dice_coef: 0.9300 - val_loss: 0.2377 - val_acc: 0.9981 - val_dice_coef: 0.7623\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.21891\n",
      "Epoch 27/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0788 - acc: 0.9992 - dice_coef: 0.9212 - val_loss: 0.2324 - val_acc: 0.9982 - val_dice_coef: 0.7676\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.21891\n",
      "Epoch 28/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0701 - acc: 0.9992 - dice_coef: 0.9299 - val_loss: 0.2371 - val_acc: 0.9980 - val_dice_coef: 0.7629\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.21891\n",
      "Epoch 29/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0733 - acc: 0.9992 - dice_coef: 0.9267 - val_loss: 0.2294 - val_acc: 0.9983 - val_dice_coef: 0.7706\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.21891\n",
      "Epoch 30/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0732 - acc: 0.9992 - dice_coef: 0.9268 - val_loss: 0.2314 - val_acc: 0.9982 - val_dice_coef: 0.7686\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.21891\n",
      "Train on 2116 samples, validate on 192 samples\n",
      "Epoch 1/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0770 - acc: 0.9991 - dice_coef: 0.9230 - val_loss: 0.0602 - val_acc: 0.9993 - val_dice_coef: 0.9398\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06020, saving model to weights/weights-10crs-01ep-0.06loss.hdf5\n",
      "Epoch 2/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0852 - acc: 0.9991 - dice_coef: 0.9148 - val_loss: 0.0603 - val_acc: 0.9993 - val_dice_coef: 0.9397\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06020\n",
      "Epoch 3/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0781 - acc: 0.9991 - dice_coef: 0.9219 - val_loss: 0.0600 - val_acc: 0.9993 - val_dice_coef: 0.9400\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.06020 to 0.05998, saving model to weights/weights-10crs-03ep-0.06loss.hdf5\n",
      "Epoch 4/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0782 - acc: 0.9991 - dice_coef: 0.9218 - val_loss: 0.0638 - val_acc: 0.9992 - val_dice_coef: 0.9362\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05998\n",
      "Epoch 5/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.0801 - acc: 0.9992 - dice_coef: 0.9199 - val_loss: 0.0630 - val_acc: 0.9992 - val_dice_coef: 0.9370\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05998\n",
      "Epoch 6/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.0848 - acc: 0.9992 - dice_coef: 0.9152 - val_loss: 0.0631 - val_acc: 0.9992 - val_dice_coef: 0.9369\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05998\n",
      "Epoch 7/30\n",
      "2116/2116 [==============================] - 270s 128ms/step - loss: 0.0728 - acc: 0.9992 - dice_coef: 0.9272 - val_loss: 0.0631 - val_acc: 0.9992 - val_dice_coef: 0.9369\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05998\n",
      "Epoch 8/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.0756 - acc: 0.9992 - dice_coef: 0.9244 - val_loss: 0.0647 - val_acc: 0.9992 - val_dice_coef: 0.9353\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05998\n",
      "Epoch 9/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.0831 - acc: 0.9992 - dice_coef: 0.9169 - val_loss: 0.0622 - val_acc: 0.9992 - val_dice_coef: 0.9378\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05998\n",
      "Epoch 10/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0803 - acc: 0.9992 - dice_coef: 0.9197 - val_loss: 0.0636 - val_acc: 0.9992 - val_dice_coef: 0.9364\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05998\n",
      "Epoch 11/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0731 - acc: 0.9992 - dice_coef: 0.9269 - val_loss: 0.0701 - val_acc: 0.9991 - val_dice_coef: 0.9299\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.05998\n",
      "Epoch 12/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0783 - acc: 0.9992 - dice_coef: 0.9217 - val_loss: 0.0689 - val_acc: 0.9991 - val_dice_coef: 0.9311\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.05998\n",
      "Epoch 13/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0794 - acc: 0.9992 - dice_coef: 0.9206 - val_loss: 0.0664 - val_acc: 0.9992 - val_dice_coef: 0.9336\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.05998\n",
      "Epoch 14/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0744 - acc: 0.9992 - dice_coef: 0.9256 - val_loss: 0.0739 - val_acc: 0.9991 - val_dice_coef: 0.9261\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.05998\n",
      "Epoch 15/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0757 - acc: 0.9992 - dice_coef: 0.9243 - val_loss: 0.0654 - val_acc: 0.9992 - val_dice_coef: 0.9346\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.05998\n",
      "Epoch 16/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0770 - acc: 0.9992 - dice_coef: 0.9230 - val_loss: 0.0667 - val_acc: 0.9992 - val_dice_coef: 0.9333\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.05998\n",
      "Epoch 17/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0752 - acc: 0.9992 - dice_coef: 0.9248 - val_loss: 0.0645 - val_acc: 0.9992 - val_dice_coef: 0.9355\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.05998\n",
      "Epoch 18/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0803 - acc: 0.9992 - dice_coef: 0.9197 - val_loss: 0.0678 - val_acc: 0.9991 - val_dice_coef: 0.9322\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.05998\n",
      "Epoch 19/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0780 - acc: 0.9992 - dice_coef: 0.9220 - val_loss: 0.0646 - val_acc: 0.9992 - val_dice_coef: 0.9354\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.05998\n",
      "Epoch 20/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0839 - acc: 0.9992 - dice_coef: 0.9161 - val_loss: 0.0657 - val_acc: 0.9992 - val_dice_coef: 0.9343\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.05998\n",
      "Epoch 21/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.0713 - acc: 0.9992 - dice_coef: 0.9287 - val_loss: 0.0665 - val_acc: 0.9992 - val_dice_coef: 0.9335\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.05998\n",
      "Epoch 22/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.0711 - acc: 0.9992 - dice_coef: 0.9289 - val_loss: 0.0662 - val_acc: 0.9992 - val_dice_coef: 0.9338\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.05998\n",
      "Epoch 23/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.0775 - acc: 0.9992 - dice_coef: 0.9225 - val_loss: 0.0699 - val_acc: 0.9991 - val_dice_coef: 0.9301\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.05998\n",
      "Epoch 24/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.0755 - acc: 0.9992 - dice_coef: 0.9245 - val_loss: 0.0688 - val_acc: 0.9991 - val_dice_coef: 0.9312\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.05998\n",
      "Epoch 25/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.0735 - acc: 0.9992 - dice_coef: 0.9265 - val_loss: 0.0686 - val_acc: 0.9991 - val_dice_coef: 0.9314\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.05998\n",
      "Epoch 26/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.0660 - acc: 0.9992 - dice_coef: 0.9340 - val_loss: 0.0674 - val_acc: 0.9991 - val_dice_coef: 0.9326\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.05998\n",
      "Epoch 27/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0708 - acc: 0.9992 - dice_coef: 0.9292 - val_loss: 0.0667 - val_acc: 0.9992 - val_dice_coef: 0.9333\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.05998\n",
      "Epoch 28/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0716 - acc: 0.9992 - dice_coef: 0.9284 - val_loss: 0.0683 - val_acc: 0.9992 - val_dice_coef: 0.9317\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.05998\n",
      "Epoch 29/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0772 - acc: 0.9992 - dice_coef: 0.9228 - val_loss: 0.0722 - val_acc: 0.9991 - val_dice_coef: 0.9278\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.05998\n",
      "Epoch 30/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0706 - acc: 0.9992 - dice_coef: 0.9294 - val_loss: 0.0738 - val_acc: 0.9991 - val_dice_coef: 0.9262\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.05998\n",
      "Train on 2116 samples, validate on 192 samples\n",
      "Epoch 1/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0711 - acc: 0.9992 - dice_coef: 0.9289 - val_loss: 0.1837 - val_acc: 0.9996 - val_dice_coef: 0.8163\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18366, saving model to weights/weights-11crs-01ep-0.18loss.hdf5\n",
      "Epoch 2/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0716 - acc: 0.9992 - dice_coef: 0.9284 - val_loss: 0.1813 - val_acc: 0.9996 - val_dice_coef: 0.8187\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.18366 to 0.18125, saving model to weights/weights-11crs-02ep-0.18loss.hdf5\n",
      "Epoch 3/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0727 - acc: 0.9992 - dice_coef: 0.9273 - val_loss: 0.1809 - val_acc: 0.9996 - val_dice_coef: 0.8191\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.18125 to 0.18095, saving model to weights/weights-11crs-03ep-0.18loss.hdf5\n",
      "Epoch 4/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0729 - acc: 0.9992 - dice_coef: 0.9271 - val_loss: 0.1835 - val_acc: 0.9996 - val_dice_coef: 0.8165\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.18095\n",
      "Epoch 5/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0679 - acc: 0.9992 - dice_coef: 0.9321 - val_loss: 0.1828 - val_acc: 0.9996 - val_dice_coef: 0.8172\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.18095\n",
      "Epoch 6/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0689 - acc: 0.9992 - dice_coef: 0.9311 - val_loss: 0.1824 - val_acc: 0.9996 - val_dice_coef: 0.8176\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.18095\n",
      "Epoch 7/30\n",
      "2116/2116 [==============================] - 269s 127ms/step - loss: 0.0687 - acc: 0.9992 - dice_coef: 0.9313 - val_loss: 0.1832 - val_acc: 0.9996 - val_dice_coef: 0.8168\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.18095\n",
      "Epoch 8/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.0709 - acc: 0.9992 - dice_coef: 0.9291 - val_loss: 0.1807 - val_acc: 0.9996 - val_dice_coef: 0.8193\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.18095 to 0.18072, saving model to weights/weights-11crs-08ep-0.18loss.hdf5\n",
      "Epoch 9/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.0705 - acc: 0.9992 - dice_coef: 0.9295 - val_loss: 0.1814 - val_acc: 0.9996 - val_dice_coef: 0.8186\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.18072\n",
      "Epoch 10/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.0706 - acc: 0.9992 - dice_coef: 0.9294 - val_loss: 0.1814 - val_acc: 0.9996 - val_dice_coef: 0.8186\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.18072\n",
      "Epoch 11/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.0666 - acc: 0.9992 - dice_coef: 0.9334 - val_loss: 0.1844 - val_acc: 0.9996 - val_dice_coef: 0.8156\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.18072\n",
      "Epoch 12/30\n",
      "2116/2116 [==============================] - 270s 127ms/step - loss: 0.0683 - acc: 0.9992 - dice_coef: 0.9317 - val_loss: 0.1833 - val_acc: 0.9996 - val_dice_coef: 0.8167\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.18072\n",
      "Epoch 13/30\n",
      " 226/2116 [==>...........................] - ETA: 3:53 - loss: 0.0706 - acc: 0.9992 - dice_coef: 0.9294"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/dlbox/anaconda3/envs/TF2-NT/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-10-7306309ceda8>\", line 1, in <module>\n",
      "    train_denceunet()\n",
      "  File \"<ipython-input-9-b8ae64296446>\", line 71, in train_denceunet\n",
      "    learning_history = model.fit(X_tra, Y_tra, batch_size=BATCH_SIZE, epochs=NUM_EPOCH, callbacks=[cp], validation_data=(X_eval, Y_eval))\n",
      "  File \"/home/dlbox/anaconda3/envs/TF2-NT/lib/python3.6/site-packages/keras/engine/training.py\", line 1039, in fit\n",
      "    validation_steps=validation_steps)\n",
      "  File \"/home/dlbox/anaconda3/envs/TF2-NT/lib/python3.6/site-packages/keras/engine/training_arrays.py\", line 199, in fit_loop\n",
      "    outs = f(ins_batch)\n",
      "  File \"/home/dlbox/anaconda3/envs/TF2-NT/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2715, in __call__\n",
      "    return self._call(inputs)\n",
      "  File \"/home/dlbox/anaconda3/envs/TF2-NT/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2675, in _call\n",
      "    fetched = self._callable_fn(*array_vals)\n",
      "  File \"/home/dlbox/anaconda3/envs/TF2-NT/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1451, in __call__\n",
      "    self._session._session, self._handle, args, status, None)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dlbox/anaconda3/envs/TF2-NT/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dlbox/anaconda3/envs/TF2-NT/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/dlbox/anaconda3/envs/TF2-NT/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/dlbox/anaconda3/envs/TF2-NT/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/dlbox/anaconda3/envs/TF2-NT/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/dlbox/anaconda3/envs/TF2-NT/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/dlbox/anaconda3/envs/TF2-NT/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/dlbox/anaconda3/envs/TF2-NT/lib/python3.6/inspect.py\", line 732, in getmodule\n",
      "    for modname, module in list(sys.modules.items()):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_denceunet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Preprocess/mhd/L0.mhd',\n",
       " '../Preprocess/mhd/L0.raw',\n",
       " '../Preprocess/mhd/L1.mhd',\n",
       " '../Preprocess/mhd/L1.raw',\n",
       " '../Preprocess/mhd/L3.mhd',\n",
       " '../Preprocess/mhd/L3.raw',\n",
       " '../Preprocess/mhd/L4.mhd',\n",
       " '../Preprocess/mhd/L4.raw',\n",
       " '../Preprocess/mhd/M0.mhd',\n",
       " '../Preprocess/mhd/M0.raw',\n",
       " '../Preprocess/mhd/M1.mhd',\n",
       " '../Preprocess/mhd/M1.raw',\n",
       " '../Preprocess/mhd/M2.mhd',\n",
       " '../Preprocess/mhd/M2.raw',\n",
       " '../Preprocess/mhd/M3.mhd',\n",
       " '../Preprocess/mhd/M3.raw',\n",
       " '../Preprocess/mhd/M4.mhd',\n",
       " '../Preprocess/mhd/M4.raw',\n",
       " '../Preprocess/mhd/M5.mhd',\n",
       " '../Preprocess/mhd/M5.raw',\n",
       " '../Preprocess/mhd/S0.mhd',\n",
       " '../Preprocess/mhd/S0.raw',\n",
       " '../Preprocess/mhd/S1.mhd',\n",
       " '../Preprocess/mhd/S1.raw',\n",
       " '../Preprocess/mhd/S2.mhd',\n",
       " '../Preprocess/mhd/S2.raw',\n",
       " '../Preprocess/mhd/S3.mhd',\n",
       " '../Preprocess/mhd/S3.raw',\n",
       " '../Preprocess/mhd/S4.mhd',\n",
       " '../Preprocess/mhd/S4.raw']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "from natsort import natsorted\n",
    "natsorted(glob.glob('../Preprocess/mhd/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2-NT",
   "language": "python",
   "name": "tf2-nt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
